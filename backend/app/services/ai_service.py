import openai
from app.services.config_service import ConfigService
from app.utils.logger import logger

class AIService:
    _client = None
    _config_cache = {}

    @classmethod
    async def get_config(cls):
        """è·å– AI ç›¸å…³é…ç½®"""
        provider = await ConfigService.get("ai_provider", "openai")
        api_key = await ConfigService.get("ai_api_key", "")
        base_url = await ConfigService.get("ai_base_url", "https://api.openai.com/v1")
        model = await ConfigService.get("ai_model", "gpt-3.5-turbo")
        use_proxy = await ConfigService.get("ai_use_proxy", False)
        
        # è·å–å…¨å±€ä»£ç†é…ç½®
        proxy_config = await ConfigService.get("proxy", {})
        
        return {
            "provider": provider,
            "api_key": api_key,
            "base_url": base_url,
            "model": model,
            "use_proxy": use_proxy,
            "proxy_url": proxy_config.get("url") if proxy_config.get("enabled") else None
        }

    @classmethod
    async def _get_client(cls):
        """è·å–æˆ–åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        config = await cls.get_config()
        
        # ç®€å•ç¼“å­˜æ£€æŸ¥ï¼Œå¦‚æœé…ç½®å˜æ›´åˆ™é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯
        # Cache key éœ€è¦åŒ…å«ä»£ç†è®¾ç½®ï¼Œä»¥ä¾¿åˆ‡æ¢ä»£ç†æ—¶é‡ç½®
        current_cache_key = f"{config['provider']}|{config['api_key']}|{config['base_url']}|{config['use_proxy']}|{config['proxy_url']}"
        
        if cls._client is None or cls._config_cache.get("key_hash") != current_cache_key:
            # å¯¹äº Ollamaï¼ŒAPI Key å¯ä»¥ä¸ºç©º
            if config['provider'] == 'openai' and not config["api_key"]:
                return None
            
            # å¦‚æœæ˜¯ Ollama ä¸”æ²¡å¡« keyï¼Œç»™ä¸€ä¸ªå ä½ç¬¦ï¼Œå› ä¸º SDK å¾€å¾€è¦æ±‚æœ‰å€¼
            api_key = config["api_key"] if config["api_key"] else "ollama"
            
            # ä»£ç†è®¾ç½®
            http_client = None
            if config["use_proxy"] and config["proxy_url"]:
                try:
                    import httpx
                    logger.info(f"ğŸ¤– [AI Init] ä½¿ç”¨å†…ç½®ä»£ç†: {config['proxy_url']}")
                    http_client = httpx.AsyncClient(proxy=config["proxy_url"])
                except Exception as e:
                    logger.error(f"âŒ [AI Init] ä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")
            
            cls._client = openai.AsyncOpenAI(
                api_key=api_key,
                base_url=config["base_url"],
                http_client=http_client
            )
            cls._config_cache["key_hash"] = current_cache_key
            
        return cls._client

    @classmethod
    async def chat_completion(cls, messages: list):
        """å‘é€èŠå¤©è¯·æ±‚"""
        client = await cls._get_client()
        if not client:
            raise ValueError("AI API Key not configured")

        config = await cls.get_config()
        
        proxy_msg = f" | ğŸŒ ä»£ç†: {config['proxy_url']}" if config.get("use_proxy") and config.get("proxy_url") else ""
        logger.info(f"ğŸ¤– [AIè¯·æ±‚] Provider: {config['provider']}, Model: {config['model']}{proxy_msg}")
        logger.debug(f"ğŸ’¬ [AIå†…å®¹] Messages: {messages}")
        
        try:
            response = await client.chat.completions.create(
                model=config["model"],
                messages=messages,
                stream=True  # å¯ç”¨æµå¼å“åº”
            )
            return response
        except Exception as e:
            logger.error(f"âŒ [AIé”™è¯¯] {str(e)}")
            raise e

    @classmethod
    async def chat_json(cls, messages: list):
        """å‘é€èŠå¤©è¯·æ±‚å¹¶è·å–å®Œæ•´çš„ JSON å“åº” (å†…éƒ¨é€»è¾‘ä½¿ç”¨)"""
        client = await cls._get_client()
        if not client:
            raise ValueError("AI API Key not configured")

        config = await cls.get_config()
        
        proxy_msg = f" | ğŸŒ ä»£ç†: {config['proxy_url']}" if config.get("use_proxy") and config.get("proxy_url") else ""
        logger.info(f"ğŸ¤– [AI JSONè¯·æ±‚] Model: {config['model']}{proxy_msg}")
        
        try:
            response = await client.chat.completions.create(
                model=config["model"],
                messages=messages,
                stream=False,
                response_format={ "type": "json_object" } if config['provider'] == 'openai' else None
            )
            content = response.choices[0].message.content
            return content
        except Exception as e:
            logger.error(f"âŒ [AI JSONè¯·æ±‚é”™è¯¯] {str(e)}")
            raise e
