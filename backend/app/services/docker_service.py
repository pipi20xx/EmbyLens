import docker
import paramiko
import os
import time
from typing import List, Dict, Any, Optional
from app.utils.logger import logger
from app.core.config_manager import get_config

# --- æ·±åº¦è¡¥ä¸ï¼šå½»åº•è§£å†³ known_hosts å’Œ å¯†ç æ”¯æŒé—®é¢˜ ---

# 1. å¼ºåˆ¶ç­–ç•¥è¡¥ä¸ï¼šç¦æ­¢æ‹’ç»æ–°ä¸»æœº
_original_set_policy = paramiko.SSHClient.set_missing_host_key_policy
def _forced_set_policy(self, policy):
    return _original_set_policy(self, paramiko.AutoAddPolicy())
paramiko.SSHClient.set_missing_host_key_policy = _forced_set_policy

# 2. å¯†ç æ³¨å…¥è¡¥ä¸
_original_connect = paramiko.SSHClient.connect
def _patched_connect(self, hostname, port=22, username=None, password=None, **kwargs):
    if not password:
        config = get_config()
        hosts = config.get("docker_hosts", [])
        host_match = next((h for h in hosts if h.get("ssh_host") == hostname), None)
        if host_match and host_match.get("ssh_pass"):
            password = host_match.get("ssh_pass")
    
    kwargs['allow_agent'] = False
    kwargs['look_for_keys'] = False
    return _original_connect(self, hostname, port=port, username=username, password=password, **kwargs)

paramiko.SSHClient.connect = _patched_connect

# --- Service å®ç° ---

class DockerService:
    def __init__(self, host_config: Dict[str, Any]):
        self.host_config = host_config
        self.client = self._get_client()

    def _get_client(self):
        try:
            host_type = self.host_config.get("type", "local")
            if host_type == "local":
                return docker.from_env()
            
            elif host_type == "ssh":
                ssh_host = self.host_config.get("ssh_host")
                ssh_user = self.host_config.get("ssh_user", "root")
                ssh_port = self.host_config.get("ssh_port", 22)
                base_url = f"ssh://{ssh_user}@{ssh_host}:{ssh_port}"
                return docker.DockerClient(base_url=base_url, use_ssh_client=False, timeout=15)
            
            elif host_type == "tcp":
                host = self.host_config.get("ssh_host")
                port = self.host_config.get("ssh_port", 2375)
                use_tls = self.host_config.get("use_tls", False)
                protocol = "https" if use_tls else "http"
                base_url = f"{protocol}://{host}:{port}"
                return docker.DockerClient(base_url=base_url)
                
            return None
        except Exception as e:
            logger.error(f"Failed to connect to Docker host {self.host_config.get('name')}: {e}")
            return None

    def list_containers(self, all=True, filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        # ä¼˜å…ˆå°è¯•é€šè¿‡ docker-py å®¢æˆ·ç«¯è·å–ï¼ˆæ•ˆç‡é«˜ï¼Œæ•°æ®å…¨ï¼‰
        if self.client:
            try:
                # ä¼ å…¥ filters å‚æ•°
                containers = self.client.containers.list(all=all, filters=filters)
                return [{
                    "id": c.short_id,
                    "full_id": c.id,
                    "name": c.name,
                    "image": c.image.tags[0] if c.image.tags else c.image.id,
                    "status": c.status,
                    "created": c.attrs.get("Created"),
                    "ports": c.attrs.get("NetworkSettings", {}).get("Ports", {})
                } for c in containers]
            except Exception as e:
                logger.warning(f"Docker-py client failed, falling back to SSH Shell: {e}")

        # å¦‚æœå®¢æˆ·ç«¯ä¸å¯ç”¨æˆ–æŠ¥é”™ï¼Œé€šè¿‡ SSH æ‰§è¡Œ docker ps å‘½ä»¤è§£æ (çº¯ SSH æ¨¡å¼)
        if self.host_config.get("type") == "ssh":
            cmd = "docker ps -a --format '{{json .}}'" if all else "docker ps --format '{{json .}}'"
            res = self.exec_command(cmd)
            if res["success"]:
                try:
                    import json
                    lines = res["stdout"].strip().split('\n')
                    results = []
                    for line in lines:
                        if not line: continue
                        c = json.loads(line)
                        results.append({
                            "id": c.get("ID"),
                            "full_id": c.get("ID"),
                            "name": c.get("Names"),
                            "image": c.get("Image"),
                            "status": c.get("Status").lower().split(' ')[0], # "Up 2 hours" -> "up"
                            "created": c.get("CreatedAt"),
                            "ports": c.get("Ports")
                        })
                    return results
                except Exception as e:
                    logger.error(f"Failed to parse docker ps output: {e}")
        return []

    def container_action(self, container_id: str, action: str):
        if not self.client: return False
        try:
            container = self.client.containers.get(container_id)
            if action == "start": container.start()
            elif action == "stop": container.stop()
            elif action == "restart": container.restart()
            elif action == "remove": container.remove(force=True)
            elif action in ["recreate", "update"]:
                attrs = container.attrs
                image_tag = attrs['Config']['Image']
                name = attrs['Name'].lstrip('/')
                
                # æ— è®º recreate è¿˜æ˜¯ updateï¼Œéƒ½æ‰§è¡Œ pullï¼ˆä¿æŒä¸ç½‘é¡µç‰ˆé€»è¾‘ä¸€è‡´ï¼‰
                logger.info(f"ğŸ“¥ [Docker] æ­£åœ¨ä¸ºå®¹å™¨ {name} æ‹‰å–æœ€æ–°é•œåƒ: {image_tag}")
                try:
                    self.client.images.pull(image_tag)
                except Exception as e:
                    logger.warning(f"âš ï¸ [Docker] æ‹‰å–é•œåƒå¤±è´¥ï¼Œå°†å°è¯•ä½¿ç”¨æœ¬åœ°é•œåƒ: {e}")

                # æå–å®Œæ•´é…ç½®
                config = attrs.get('Config', {})
                host_config = attrs.get('HostConfig', {})
                
                # è½¬æ¢ç«¯å£æ˜ å°„æ ¼å¼ (docker-py run éœ€è¦æ ¼å¼: { 'container_port/proto': 'host_port' })
                port_bindings = host_config.get('PortBindings') or {}
                ports = {}
                if port_bindings:
                    for container_port, host_ports in port_bindings.items():
                        if host_ports:
                            ports[container_port] = host_ports[0].get('HostPort')
                
                network_mode = host_config.get('NetworkMode', 'bridge')
                
                # ä¿®å¤ï¼šå¦‚æœç½‘ç»œæ¨¡å¼æ˜¯ hostï¼Œåˆ™ä¸èƒ½ä¼ é€’ ports å‚æ•°ï¼Œå¦åˆ™æŠ¥é”™
                if network_mode == "host":
                    ports = None

                create_kwargs = {
                    "image": image_tag,
                    "name": name,
                    "detach": True,
                    "environment": config.get('Env', []),
                    "volumes": host_config.get('Binds', []),
                    "ports": ports,
                    "restart_policy": host_config.get('RestartPolicy', {}),
                    "network_mode": network_mode,
                    "command": config.get('Cmd'),
                    "entrypoint": config.get('Entrypoint'),
                    "working_dir": config.get('WorkingDir'),
                    "user": config.get('User'),
                    "hostname": config.get('Hostname'),
                    "mac_address": config.get('MacAddress'),
                    "labels": config.get('Labels')
                }
                
                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŸå®¹å™¨æœ‰ç‰¹æƒï¼Œæ–°å®¹å™¨ä¹Ÿè¦æœ‰
                if host_config.get('Privileged'):
                    create_kwargs["privileged"] = True

                # å®‰å…¨é‡æ„ç­–ç•¥ï¼šå…ˆé‡å‘½åæ—§å®¹å™¨ï¼Œå¤±è´¥åˆ™å›æ»š
                old_name = container.name
                bak_name = f"{old_name}_lens_bak_{int(time.time())}"
                
                try:
                    container.stop()
                    container.rename(bak_name)
                    
                    # åˆ›å»ºå¹¶å¯åŠ¨æ–°å®¹å™¨
                    self.client.containers.run(**create_kwargs)
                    
                    # æ–°å®¹å™¨å¯åŠ¨æˆåŠŸï¼Œåˆ é™¤å¤‡ä»½
                    container.remove(force=True)
                    logger.info(f"âœ¨ [Docker] å®¹å™¨ {old_name} é‡æ„æˆåŠŸï¼Œå·²æ¸…ç†æ—§å®¹å™¨")
                except Exception as run_err:
                    logger.error(f"âŒ [Docker] æ–°å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œå°è¯•å›æ»š: {run_err}")
                    # å°è¯•æ¢å¤æ—§å®¹å™¨
                    try:
                        # æ£€æŸ¥æ–°å®¹å™¨æ˜¯å¦å·²åŠé€”åˆ›å»ºï¼ˆå¦‚æœåˆ›å»ºäº†ä½†æ²¡å¯åŠ¨æˆåŠŸï¼Œä¹Ÿéœ€è¦æ¸…ç†æ‰åç§°å ä½ï¼‰
                        try:
                            failed_new = self.client.containers.get(old_name)
                            failed_new.remove(force=True)
                        except: pass
                        
                        container.rename(old_name)
                        container.start()
                        logger.info(f"âª [Docker] å·²æˆåŠŸå›æ»šè‡³æ—§å®¹å™¨ {old_name}")
                    except Exception as rollback_err:
                        logger.error(f"ğŸš¨ [Docker] å›æ»šå¤±è´¥! æ—§å®¹å™¨ç›®å‰åç§°ä¸º {bak_name}: {rollback_err}")
                    raise run_err
            return True
        except Exception as e:
            logger.error(f"Error performing action {action} on container {container_id}: {e}")
            return False

    def get_container_logs(self, container_id: str, tail=100) -> str:
        if not self.client: return "Not connected to Docker"
        try:
            container = self.client.containers.get(container_id)
            return container.logs(tail=tail).decode("utf-8")
        except Exception as e:
            return str(e)

    async def get_image_update_info(self, image_tag: str):
        """
        è·å–é•œåƒçš„æ›´æ–°ä¿¡æ¯ã€‚æ”¯æŒ Docker Hub ä»¥åŠç¬¬ä¸‰æ–¹ä»“åº“ (å¦‚ lscr.io, ghcr.io)ã€‚
        """
        if not image_tag: return None
        
        # 1. è§£æé•œåƒåä¸ä»“åº“åœ°å€
        # lscr.io/linuxserver/qbittorrent:latest -> host=lscr.io, repo=linuxserver/qbittorrent, tag=latest
        # nginx -> host=registry-1.docker.io, repo=library/nginx, tag=latest
        parts = image_tag.split("/")
        host = "registry-1.docker.io"
        repo = ""
        tag = "latest"
        
        full_repo_path = image_tag
        if ":" in image_tag:
            full_repo_path, tag = image_tag.rsplit(":", 1)
            
        if "." in parts[0] or ":" in parts[0]:
            host = parts[0]
            repo = "/".join(parts[1:])
            if ":" in repo: repo = repo.rsplit(":", 1)[0]
        else:
            repo = full_repo_path
            if "/" not in repo:
                repo = f"library/{repo}"
        
        # ä¿®æ­£ Docker Hub çš„ä¸»æœºå
        reg_host = host
        if host == "docker.io": reg_host = "registry-1.docker.io"
            
        # 2. è·å–æœ¬åœ° RepoDigests
        local_digests = []
        res = self.exec_command(f"docker inspect --format='{{{{json .RepoDigests}}}}' {image_tag}", log_error=False)
        if res["success"] and res["stdout"].strip():
            try:
                import json
                local_digests = json.loads(res["stdout"])
            except: pass
            
        if not local_digests and self.client:
            try:
                img = self.client.images.get(image_tag)
                local_digests = img.attrs.get("RepoDigests", [])
            except: pass
            
        # 3. åŠ¨æ€è·å–è¿œç¨‹ Digest (æ”¯æŒ OCI æŒ‘æˆ˜è®¤è¯)
        remote_digest = ""
        try:
            from app.utils.http_client import get_async_client
            # æ‰©å±• Accept å¤´ï¼Œæ”¯æŒå¤šæ¶æ„é•œåƒæ¸…å•
            accept_headers = (
                "application/vnd.docker.distribution.manifest.v2+json, "
                "application/vnd.docker.distribution.manifest.list.v2+json, "
                "application/vnd.oci.image.manifest.v1+json, "
                "application/vnd.oci.image.index.v1+json"
            )
            
            async with get_async_client(timeout=15.0) as client:
                manifest_url = f"https://{reg_host}/v2/{repo}/manifests/{tag}"
                headers = {"Accept": accept_headers}
                
                # æ˜¾å¼å¼€å¯é‡å®šå‘è·Ÿéš
                res = await client.get(manifest_url, headers=headers, follow_redirects=True)
                
                if res.status_code == 401:
                    auth_header = res.headers.get("WWW-Authenticate", "")
                    if "Bearer" in auth_header:
                        import re
                        realm = re.search(r'realm="([^"]+)"', auth_header).group(1)
                        service_match = re.search(r'service="([^"]+)"', auth_header)
                        service = service_match.group(1) if service_match else ""
                        scope_match = re.search(r'scope="([^"]+)"', auth_header)
                        scope = scope_match.group(1) if scope_match else f"repository:{repo}:pull"
                        
                        auth_params = {"scope": scope}
                        if service: auth_params["service"] = service
                        
                        auth_res = await client.get(realm, params=auth_params, follow_redirects=True)
                        if auth_res.status_code == 200:
                            token = auth_res.json().get("token") or auth_res.json().get("access_token")
                            headers["Authorization"] = f"Bearer {token}"
                            res = await client.get(manifest_url, headers=headers, follow_redirects=True)
                
                if res.status_code == 200:
                    remote_digest = res.headers.get("Docker-Content-Digest", "")
                else:
                    logger.debug(f"HTTP {res.status_code} for {manifest_url}")
        except Exception as e:
            logger.warning(f"Failed to fetch remote digest for {image_tag} on {host}: {e}")

        # 4. å¯¹æ¯”åˆ¤å®š
        has_update = False
        if remote_digest:
            is_latest = any(remote_digest in d for d in local_digests)
            has_update = not is_latest
            status_text = "å‘ç°æ–°ç‰ˆæœ¬" if has_update else "å·²æ˜¯æœ€æ–°"
            logger.info(f"ğŸ” [é•œåƒæ£€æµ‹] ç«™ç‚¹: {host} | é•œåƒ: {repo}:{tag}")
            logger.info(f"   â”£ æœ¬åœ°æŒ‡çº¹: {local_digests}")
            logger.info(f"   â”£ è¿œç¨‹æŒ‡çº¹: {remote_digest}")
            logger.info(f"   â”— åˆ¤å®šç»“æœ: {status_text}")
        else:
            logger.warning(f"âš ï¸ [é•œåƒæ£€æµ‹] æ— æ³•è·å–è¿œç¨‹æŒ‡çº¹: {image_tag} (Host: {host})")

        return {
            "image": image_tag,
            "local_digests": local_digests,
            "remote_digest": remote_digest,
            "has_update": has_update
        }

    @staticmethod
    async def run_auto_update_task():
        """
        æè‡´ç²¾å‡†ç‰ˆï¼šæ ¹æ®è®°å½•ä¸­çš„ host_id ç›´æ¥å®šç‚¹æ›´æ–°
        """
        logger.info("ğŸš€ [Docker] å¼€å§‹æ‰§è¡Œæ¯æ—¥è‡ªåŠ¨æ›´æ–°ä»»åŠ¡...")
        from app.core.config_manager import get_config
        from app.services.notification_service import NotificationService
        
        config = get_config()
        # æ£€æŸ¥æ˜¯å¦å…¨å±€å¼€å¯äº†è‡ªåŠ¨æ›´æ–°
        auto_settings = config.get("docker_auto_update_settings", {"enabled": True})
        if not auto_settings.get("enabled"):
            logger.info("â„¹ï¸ [Docker] è‡ªåŠ¨æ›´æ–°å·²å…¨å±€å…³é—­ï¼Œè·³è¿‡æ‰§è¡Œã€‚")
            return

        all_hosts = config.get("docker_hosts", [])
        container_settings = config.get("docker_container_settings", {})
        
        # 1. ç­›é€‰å‡ºæ‰€æœ‰å¼€å¯äº†è‡ªåŠ¨æ›´æ–°ä¸”æœ‰ host_id çš„è®°å½•
        tasks_by_host = {}
        for name, settings in container_settings.items():
            if settings.get("auto_update") and settings.get("host_id"):
                h_id = settings.get("host_id")
                if h_id not in tasks_by_host:
                    tasks_by_host[h_id] = []
                tasks_by_host[h_id].append(name)
        
        if not tasks_by_host:
            logger.info("â„¹ï¸ [Docker] æ²¡æœ‰å‘ç°å¾…æ›´æ–°çš„ä»»åŠ¡è®°å½•ï¼Œä»»åŠ¡ç»“æŸã€‚")
            return

        updated_count = 0
        error_count = 0

        # 2. å®šç‚¹æ‰§è¡Œ
        for h_id, names in tasks_by_host.items():
            host_config = next((h for h in all_hosts if h.get("id") == h_id), None)
            if not host_config:
                logger.error(f"âŒ [Docker] æ‰¾ä¸åˆ° ID ä¸º {h_id} çš„ä¸»æœºé…ç½®ï¼Œè·³è¿‡å®¹å™¨: {names}")
                continue

            host_name = host_config.get("name", "Unknown")
            logger.info(f"ğŸŒ [Docker] æ­£åœ¨è¿æ¥ä¸»æœº [{host_name}] æ£€æŸ¥å®¹å™¨: {', '.join(names)}")
            
            try:
                from app.services.docker_service import DockerService
                service = DockerService(host_config)
                containers = service.list_containers(all=True, filters={"name": names})
                
                for container in containers:
                    c_name = container.get("name")
                    if c_name in names:
                        image = container.get("image")
                        try:
                            update_info = await service.get_image_update_info(image)
                            if update_info and update_info.get("has_update"):
                                logger.info(f"âœ¨ [Docker][{host_name}] å‘ç°é•œåƒæ›´æ–°: {c_name}")
                                c_id = container.get("full_id") or container.get("id")
                                if service.container_action(c_id, "recreate"):
                                    updated_count += 1
                                    await NotificationService.emit(
                                        event="docker.auto_update",
                                        title="Docker è‡ªåŠ¨æ›´æ–°æˆåŠŸ",
                                        message=f"ä¸»æœº: {host_name}\nå®¹å™¨: {c_name}\né•œåƒ: {image}\nç»“æœ: å·²æ›´æ–°å¹¶é‡æ„"
                                    )
                                else:
                                    error_count += 1
                        except Exception as e:
                            logger.error(f"âŒ [Docker][{host_name}] å¤„ç† {c_name} å¼‚å¸¸: {e}")
                            error_count += 1
            except Exception as e:
                logger.error(f"âŒ [Docker] æ— æ³•è¿æ¥ä¸»æœº {host_name}: {e}")
                error_count += len(names)

        logger.info(f"ğŸ [Docker] è‡ªåŠ¨æ›´æ–°å®Œæ¯•ã€‚æ›´æ–°: {updated_count}, å¤±è´¥: {error_count}")

    _scheduler = None
    _is_running = False

    @classmethod
    def get_scheduler(cls):
        if cls._scheduler is None:
            from apscheduler.schedulers.asyncio import AsyncIOScheduler
            import os
            import pytz
            tz_name = os.getenv("TZ", "UTC")
            try:
                tz = pytz.timezone(tz_name)
            except Exception:
                tz = pytz.UTC
            cls._scheduler = AsyncIOScheduler(timezone=tz)
        return cls._scheduler

    @classmethod
    async def start_scheduler(cls):
        if not cls._is_running:
            cls.get_scheduler().start()
            cls._is_running = True
            logger.info("ğŸ“… [Docker] è‡ªåŠ¨æ›´æ–°è°ƒåº¦å™¨å·²å¯åŠ¨")
            await cls.reload_scheduler()

    @classmethod
    async def reload_scheduler(cls):
        """é‡è½½è°ƒåº¦å™¨è®¾ç½®"""
        from apscheduler.triggers.cron import CronTrigger
        from apscheduler.triggers.interval import IntervalTrigger
        from app.core.config_manager import get_config
        import os
        import pytz
        
        scheduler = cls.get_scheduler()
        scheduler.remove_all_jobs()
        
        config = get_config()
        settings = config.get("docker_auto_update_settings", {"enabled": True, "type": "cron", "value": "03:00"})
        
        if not settings.get("enabled"):
            logger.info("ğŸ“… [Docker] è‡ªåŠ¨æ›´æ–°å·²åœç”¨")
            return

        tz_name = os.getenv("TZ", "UTC")
        try:
            tz = pytz.timezone(tz_name)
        except Exception:
            tz = pytz.UTC

        try:
            stype = settings.get("type", "cron")
            sval = settings.get("value", "03:00")
            
            if stype == "cron":
                if ":" in sval:
                    h, m = sval.split(":")
                    trigger = CronTrigger(hour=int(h), minute=int(m), timezone=tz)
                else:
                    trigger = CronTrigger.from_crontab(sval, timezone=tz)
            else: # interval (minutes)
                trigger = IntervalTrigger(minutes=int(sval), timezone=tz)

            scheduler.add_job(
                DockerService.run_auto_update_task,
                trigger,
                id="docker_auto_update",
                replace_existing=True
            )
            logger.info(f"ğŸ“… [Docker] è‡ªåŠ¨æ›´æ–°å·²é‡è½½ ({stype}: {sval}, æ—¶åŒº: {tz_name})")
        except Exception as e:
            logger.error(f"âŒ [Docker] é‡è½½è°ƒåº¦å™¨å¤±è´¥: {e}")
        # ... (rest of the method logic)

    def test_connection(self) -> bool:
        if not self.client: return False
        try:
            return self.client.ping()
        except Exception:
            return False

    def exec_command(self, command: str, cwd: Optional[str] = None, log_error: bool = True) -> Dict[str, Any]:
        """åœ¨è¿œç¨‹æˆ–æœ¬åœ°æ‰§è¡Œ shell å‘½ä»¤"""
        import subprocess
        full_cmd = f"cd {cwd} && {command}" if cwd else command
        
        # å™ªéŸ³è¿‡æ»¤å™¨ï¼šè¿‡æ»¤æ‰é‚£äº›æ— å®³ä½†çƒ¦äººçš„ Docker è­¦å‘Š
        noise_filters = [
            "the attribute `version` is obsolete",
            "search/all: the attribute `version` is obsolete",
            "recreate: the attribute `version` is obsolete"
        ]

        def filter_noise(text: str) -> str:
            if not text: return ""
            lines = text.split('\n')
            # åªæœ‰å½“è¯¥è¡Œä¸åŒ…å«ä»»ä½•å™ªéŸ³ç‰‡æ®µæ—¶æ‰ä¿ç•™
            filtered = [line for line in lines if not any(noise in line for noise in noise_filters)]
            return '\n'.join(filtered).strip()

        if self.host_config.get("type") == "local":
            try:
                process = subprocess.run(full_cmd, shell=True, capture_output=True, text=True)
                stdout = process.stdout
                stderr = filter_noise(process.stderr)
                
                if process.returncode != 0 and log_error:
                    logger.error(f"Local Command Failed: {command} (Code: {process.returncode}, Err: {stderr})")
                return {"success": process.returncode == 0, "stdout": stdout, "stderr": stderr}
            except Exception as e:
                return {"success": False, "stdout": "", "stderr": str(e)}
        
        elif self.host_config.get("type") == "ssh":
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            try:
                ssh_host = self.host_config.get("ssh_host")
                ssh_user = self.host_config.get("ssh_user", "root")
                ssh_port = self.host_config.get("ssh_port", 22)
                ssh_pass = self.host_config.get("ssh_pass")
                
                ssh.connect(ssh_host, port=ssh_port, username=ssh_user, password=ssh_pass, timeout=10)
                stdin, stdout, stderr = ssh.exec_command(full_cmd)
                
                out = stdout.read().decode()
                err = filter_noise(stderr.read().decode())
                exit_status = stdout.channel.recv_exit_status()
                
                if exit_status != 0 and log_error:
                    logger.error(f"SSH Command Failed: {command} (Code: {exit_status}, Err: {err})")
                
                return {
                    "success": exit_status == 0,
                    "stdout": out,
                    "stderr": err
                }
            except Exception as e:
                if log_error: logger.error(f"SSH Connection Error during exec: {e}")
                return {"success": False, "stdout": "", "stderr": str(e)}
            finally:
                ssh.close()
        return {"success": False, "stdout": "", "stderr": "Unsupported host type"}

    def read_file(self, file_path: str) -> str:
        if self.host_config.get("type") == "local":
            if not os.path.exists(file_path): return ""
            with open(file_path, "r") as f: return f.read()
            
        elif self.host_config.get("type") == "ssh":
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            try:
                ssh.connect(self.host_config.get("ssh_host"), 
                            port=self.host_config.get("ssh_port", 22), 
                            username=self.host_config.get("ssh_user"), 
                            password=self.host_config.get("ssh_pass"))
                sftp = ssh.open_sftp()
                with sftp.open(file_path, 'r') as f:
                    content = f.read().decode()
                sftp.close()
                return content
            except Exception as e:
                logger.error(f"SFTP Read Error: {e}")
                return ""
            finally:
                ssh.close()
        return ""

    def write_file(self, file_path: str, content: str) -> bool:
        if self.host_config.get("type") == "local":
            try:
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                with open(file_path, "w") as f: f.write(content)
                return True
            except: return False
            
        elif self.host_config.get("type") == "ssh":
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            try:
                ssh.connect(self.host_config.get("ssh_host"), 
                            port=self.host_config.get("ssh_port", 22), 
                            username=self.host_config.get("ssh_user"), 
                            password=self.host_config.get("ssh_pass"))
                sftp = ssh.open_sftp()
                remote_dir = os.path.dirname(file_path)
                ssh.exec_command(f"mkdir -p {remote_dir}")
                with sftp.open(file_path, 'w') as f:
                    f.write(content)
                sftp.close()
                return True
            except Exception as e:
                logger.error(f"SFTP Write Error: {e}")
                return False
            finally:
                ssh.close()
        return False

    def get_container_socket(self, container_id: str, command: str = "/bin/bash"):
        """è·å–å®¹å™¨çš„äº¤äº’å¼ Socket"""
        if not self.client:
            return None
        
        try:
            # ä½¿ç”¨ APIClient ä»¥è·å¾—å¯¹åº•å±‚ socket çš„è®¿é—®æƒé™
            api_client = self.client.api
            exec_instance = api_client.exec_create(
                container_id, 
                cmd=command, 
                stdin=True, 
                stdout=True, 
                stderr=True, 
                tty=True
            )
            
            # è¿”å› socket ä¾› WebSocket ä½¿ç”¨
            sock = api_client.exec_start(exec_instance['Id'], detach=False, tty=True, stream=True, socket=True)
            return sock
        except Exception as e:
            logger.error(f"Failed to create exec socket: {e}")
            if command == "/bin/bash":
                # å°è¯•é€€å›åˆ° /bin/sh
                return self.get_container_socket(container_id, "/bin/sh")
            return None