import docker
import paramiko
import os
import time
import asyncio
from typing import List, Dict, Any, Optional
from app.utils.logger import logger
from app.core.config_manager import get_config

# --- æ·±åº¦è¡¥ä¸ï¼šå½»åº•è§£å†³ known_hosts å’Œ å¯†ç æ”¯æŒé—®é¢˜ ---

# 1. å¼ºåˆ¶ç­–ç•¥è¡¥ä¸ï¼šç¦æ­¢æ‹’ç»æ–°ä¸»æœº
_original_set_policy = paramiko.SSHClient.set_missing_host_key_policy
def _forced_set_policy(self, policy):
    return _original_set_policy(self, paramiko.AutoAddPolicy())
paramiko.SSHClient.set_missing_host_key_policy = _forced_set_policy

# 2. å¯†ç æ³¨å…¥è¡¥ä¸
_original_connect = paramiko.SSHClient.connect
def _patched_connect(self, hostname, port=22, username=None, password=None, **kwargs):
    if not password:
        config = get_config()
        hosts = config.get("docker_hosts", [])
        host_match = next((h for h in hosts if h.get("ssh_host") == hostname), None)
        if host_match and host_match.get("ssh_pass"):
            password = host_match.get("ssh_pass")
    
    kwargs['allow_agent'] = False
    kwargs['look_for_keys'] = False
    return _original_connect(self, hostname, port=port, username=username, password=password, **kwargs)

paramiko.SSHClient.connect = _patched_connect

# --- Service å®ç° ---

class DockerService:
    # ç±»çº§åˆ«ç¼“å­˜ï¼š{ host_id: (client, timestamp) }
    _clients_cache = {}
    _ssh_clients_cache = {} # { host_id: (ssh_client, timestamp) }
    _containers_cache = {} # { host_id: (data, timestamp) }
    _projects_cache = {} # { host_id: (data, timestamp) }
    
    def __init__(self, host_config: Dict[str, Any]):
        self.host_config = host_config
        self.host_id = host_config.get("id", "local")
        self.client = self._get_client()

    def _get_client(self):
        # æ£€æŸ¥æœ‰æ•ˆç¼“å­˜ (30åˆ†é’Ÿå†…æœ‰æ•ˆ)
        if self.host_id in self._clients_cache:
            client, ts = self._clients_cache[self.host_id]
            if time.time() - ts < 1800:
                try:
                    # å¿«é€Ÿæ£€æŸ¥è¿æ¥æ˜¯å¦çœŸçš„å­˜æ´»
                    client.ping()
                    return client
                except:
                    if self.host_id in self._clients_cache:
                        del self._clients_cache[self.host_id]
        
        try:
            client = None
            host_type = self.host_config.get("type", "local")
            if host_type == "local":
                client = docker.from_env()
            
            elif host_type == "ssh":
                ssh_host = self.host_config.get("ssh_host")
                ssh_user = self.host_config.get("ssh_user", "root")
                ssh_port = self.host_config.get("ssh_port", 22)
                # ä½¿ç”¨ timeout é¿å…å¡æ­»
                base_url = f"ssh://{ssh_user}@{ssh_host}:{ssh_port}"
                client = docker.DockerClient(base_url=base_url, use_ssh_client=False, timeout=10)
            
            elif host_type == "tcp":
                host = self.host_config.get("ssh_host")
                port = self.host_config.get("ssh_port", 2375)
                use_tls = self.host_config.get("use_tls", False)
                protocol = "https" if use_tls else "http"
                base_url = f"{protocol}://{host}:{port}"
                client = docker.DockerClient(base_url=base_url, timeout=10)
            
            if client:
                self._clients_cache[self.host_id] = (client, time.time())
                return client
                
            return None
        except Exception as e:
            logger.error(f"Failed to connect to Docker host {self.host_config.get('name')}: {e}")
            return None

    def list_containers(self, all=True, filters: Dict[str, Any] = None, details: bool = True) -> List[Dict[str, Any]]:
        # åªæœ‰åœ¨æ²¡æœ‰è¿‡æ»¤æ¡ä»¶çš„æƒ…å†µä¸‹ä½¿ç”¨ 5 ç§’ç¼“å­˜ï¼Œé˜²æ­¢å‰ç«¯é¢‘ç¹åˆ‡æ¢/è¯·æ±‚
        cache_key = f"{self.host_id}_{all}_{details}"
        if not filters and cache_key in self._containers_cache:
            data, ts = self._containers_cache[cache_key]
            if time.time() - ts < 5:
                return data

        results = []

        # ä¼˜å…ˆå°è¯•é€šè¿‡ docker-py å®¢æˆ·ç«¯è·å–ï¼ˆæ•ˆç‡é«˜ï¼Œæ•°æ®å…¨ï¼‰
        if self.client:
            try:
                # ä¼ å…¥ filters å‚æ•°
                containers = self.client.containers.list(all=all, filters=filters)
                for c in containers:
                    ip = ""
                    uptime_str = c.status
                    
                    if details:
                        networks = c.attrs.get("NetworkSettings", {}).get("Networks", {})
                        if networks:
                            # ä¼˜å…ˆæ‰¾ bridge æˆ–è€…ç¬¬ä¸€ä¸ª
                            if "bridge" in networks:
                                ip = networks["bridge"].get("IPAddress", "")
                            if not ip:
                                ip = next(iter(networks.values())).get("IPAddress", "")

                        # è®¡ç®—è¿è¡Œæ—¶é—´
                        import datetime
                        started_at = c.attrs.get("State", {}).get("StartedAt", "")
                        if started_at and c.status == "running":
                            try:
                                # 2024-05-22T08:34:11.123456789Z -> 2024-05-22T08:34:11
                                t_part = started_at.split('.')[0].replace('Z', '')
                                start_dt = datetime.datetime.fromisoformat(t_part)
                                delta = datetime.datetime.utcnow() - start_dt
                                days = delta.days
                                hours, remainder = divmod(delta.seconds, 3600)
                                minutes, _ = divmod(remainder, 60)
                                if days > 0: uptime_str = f"å·²è¿è¡Œ {days} å¤©"
                                elif hours > 0: uptime_str = f"å·²è¿è¡Œ {hours} å°æ—¶"
                                else: uptime_str = f"å·²è¿è¡Œ {minutes} åˆ†é’Ÿ"
                            except: pass

                    results.append({
                        "id": c.short_id,
                        "full_id": c.id,
                        "name": c.name,
                        "image": c.image.tags[0] if c.image.tags else c.image.id,
                        "status": c.status,
                        "uptime": uptime_str,
                        "created": c.attrs.get("Created"),
                        "ports": c.attrs.get("NetworkSettings", {}).get("Ports", {}),
                        "ip": ip
                    })
                
                # è·å–ç»“æœåå­˜å…¥ç¼“å­˜å¹¶è¿”å›
                if not filters:
                    self._containers_cache[cache_key] = (results, time.time())
                return results
            except Exception as e:
                logger.warning(f"Docker-py client failed, falling back to SSH Shell: {e}")

        # å¦‚æœå®¢æˆ·ç«¯ä¸å¯ç”¨æˆ–æŠ¥é”™ï¼Œé€šè¿‡ SSH æ‰§è¡Œ docker ps å‘½ä»¤è§£æ (çº¯ SSH æ¨¡å¼)
        if self.host_config.get("type") == "ssh" or self.host_config.get("type") == "local":
            cmd = "docker ps -a --format '{{json .}}'" if all else "docker ps --format '{{json .}}'"
            res = self.exec_command(cmd)
            if res["success"]:
                try:
                    import json
                    lines = res["stdout"].strip().split('\n')
                    results = []
                    for line in lines:
                        if not line: continue
                        c = json.loads(line)
                        results.append({
                            "id": c.get("ID"),
                            "full_id": c.get("ID"),
                            "name": c.get("Names"),
                            "image": c.get("Image"),
                            "status": c.get("Status").lower().split(' ')[0], # "Up 2 hours" -> "up"
                            "uptime": c.get("Status"), # åŒ…å« "Up 2 hours"
                            "created": c.get("CreatedAt"),
                            "ports": c.get("Ports"),
                            "ip": "" # ç¨åè¡¥å……
                        })
                    
                    # è¡¥å…… IP ä¿¡æ¯
                    if details:
                        ip_cmd = "docker inspect --format '{{.Name}}:{{range .NetworkSettings.Networks}}{{.IPAddress}},{{end}}' $(docker ps -aq)"
                        ip_res = self.exec_command(ip_cmd, log_error=False)
                        if ip_res["success"]:
                            ip_map = {}
                            for line in ip_res["stdout"].strip().split('\n'):
                                if ':' in line:
                                    name, ips = line.split(':', 1)
                                    name = name.lstrip('/')
                                    ip_list = [ip for ip in ips.split(',') if ip]
                                    ip_map[name] = ip_list[0] if ip_list else ""
                            
                            for r in results:
                                r["ip"] = ip_map.get(r["name"], "")

                    if not filters:
                        self._containers_cache[cache_key] = (results, time.time())
                    return results
                except Exception as e:
                    logger.error(f"Failed to parse docker ps output: {e}")
        
        return results

    def get_containers_stats(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰å®¹å™¨çš„å®æ—¶èµ„æºå ç”¨"""
        cmd = "docker stats --no-stream --format '{{json .}}'"
        res = self.exec_command(cmd, log_error=False)
        stats = {}
        if res["success"]:
            try:
                import json
                lines = res["stdout"].strip().split('\n')
                for line in lines:
                    if not line: continue
                    try:
                        s = json.loads(line)
                        name = s.get("Name")
                        if name:
                            stats[name] = {
                                "cpu": s.get("CPUPerc"),
                                "mem": s.get("MemUsage"),
                                "mem_perc": s.get("MemPerc"),
                                "net": s.get("NetIO"),
                                "block": s.get("BlockIO"),
                                "pids": s.get("PIDs")
                            }
                    except: continue
            except Exception as e:
                logger.error(f"Failed to parse docker stats: {e}")
        return stats

    def container_action(self, container_id: str, action: str):
        if not self.client: return False
        try:
            container = self.client.containers.get(container_id)
            if action == "start": container.start()
            elif action == "stop": container.stop()
            elif action == "restart": container.restart()
            elif action == "remove": container.remove(force=True)
            elif action in ["recreate", "update"]:
                attrs = container.attrs
                image_tag = attrs['Config']['Image']
                name = attrs['Name'].lstrip('/')
                
                # æ— è®º recreate è¿˜æ˜¯ updateï¼Œéƒ½æ‰§è¡Œ pullï¼ˆä¿æŒä¸ç½‘é¡µç‰ˆé€»è¾‘ä¸€è‡´ï¼‰
                logger.info(f"ğŸ“¥ [Docker] æ­£åœ¨ä¸ºå®¹å™¨ {name} æ‹‰å–æœ€æ–°é•œåƒ: {image_tag}")
                try:
                    self.client.images.pull(image_tag)
                except Exception as e:
                    logger.warning(f"âš ï¸ [Docker] æ‹‰å–é•œåƒå¤±è´¥ï¼Œå°†å°è¯•ä½¿ç”¨æœ¬åœ°é•œåƒ: {e}")

                # æå–å®Œæ•´é…ç½®
                config = attrs.get('Config', {})
                host_config = attrs.get('HostConfig', {})
                
                # --- ä¿®å¤ï¼šä¿ç•™æŒ‚è½½çš„ Propagation å±æ€§ (å¦‚ rslave) ---
                # HostConfig.Binds æœ‰æ—¶ä¼šä¸¢å¤± propagation ä¿¡æ¯ï¼Œéœ€ä» Mounts æ‰¾å›
                mounts = attrs.get('Mounts', [])
                current_binds = host_config.get('Binds') or []
                final_binds = []
                
                # 1. å»ºç«‹ç°æœ‰ Binds çš„ç´¢å¼• (Source:Dest -> Mode) 
                bind_map = {} 
                for b in current_binds:
                    parts = b.split(':')
                    if len(parts) >= 2:
                        # ç»Ÿä¸€ä½œä¸º Key: "Src:Dst"
                        key = f"{parts[0]}:{parts[1]}"
                        mode = parts[2] if len(parts) > 2 else ""
                        bind_map[key] = mode

                # 2. éå† Mounts è¡¥å…… Propagation
                for m in mounts:
                    if m.get('Type') == 'bind':
                        src = m.get('Source')
                        dst = m.get('Destination')
                        propagation = m.get('Propagation', '')
                        
                        # åªæœ‰éé»˜è®¤çš„ propagation (å¦‚ rslave, rshared) æ‰éœ€è¦æ˜¾å¼æ·»åŠ 
                        if propagation and propagation != 'rprivate':
                            key = f"{src}:{dst}"
                            if key in bind_map:
                                mode = bind_map[key]
                                # å¦‚æœç°æœ‰ mode æ²¡åŒ…å«è¯¥ propagationï¼Œåˆ™è¿½åŠ 
                                if propagation not in mode:
                                    new_mode = f"{mode},{propagation}" if mode else propagation
                                    bind_map[key] = new_mode
                            else:
                                # å¦‚æœ Binds é‡Œç¼ºå¤±è¯¥æŒ‚è½½ï¼Œå°è¯•è¡¥å› (é»˜è®¤ rw)
                                rw_mode = "rw" if m.get('RW', True) else "ro"
                                bind_map[key] = f"{rw_mode},{propagation}"

                # 3. é‡å»º Binds åˆ—è¡¨
                if not bind_map and current_binds:
                    # å¦‚æœæ²¡è§£æå‡ºä»»ä½•ä¸œè¥¿ä½†åŸ Binds ä¸ä¸ºç©º (å¯èƒ½æ˜¯æ—§ç‰ˆæœ¬ Docker æ²¡ Mounts)ï¼Œä¿ç•™åŸæ ·
                    final_binds = current_binds
                else:
                    for key, mode in bind_map.items():
                        if mode:
                            final_binds.append(f"{key}:{mode}")
                        else:
                            final_binds.append(key)
                # -------------------------------------------------

                # è½¬æ¢ç«¯å£æ˜ å°„æ ¼å¼ (docker-py run éœ€è¦æ ¼å¼: { 'container_port/proto': 'host_port' })
                port_bindings = host_config.get('PortBindings') or {}
                ports = {}
                if port_bindings:
                    for container_port, host_ports in port_bindings.items():
                        if host_ports:
                            ports[container_port] = host_ports[0].get('HostPort')
                
                network_mode = host_config.get('NetworkMode', 'bridge')
                
                # ä¿®å¤ï¼šå¦‚æœç½‘ç»œæ¨¡å¼æ˜¯ hostï¼Œåˆ™ä¸èƒ½ä¼ é€’ ports å‚æ•°ï¼Œå¦åˆ™æŠ¥é”™
                if network_mode == "host":
                    ports = None

                create_kwargs = {
                    "image": image_tag,
                    "name": name,
                    "detach": True,
                    "environment": config.get('Env', []),
                    "volumes": final_binds,
                    "ports": ports,
                    "restart_policy": host_config.get('RestartPolicy', {}),
                    "network_mode": network_mode,
                    "command": config.get('Cmd'),
                    "entrypoint": config.get('Entrypoint'),
                    "working_dir": config.get('WorkingDir'),
                    "user": config.get('User'),
                    "hostname": config.get('Hostname'),
                    "mac_address": config.get('MacAddress'),
                    "labels": config.get('Labels')
                }
                
                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŸå®¹å™¨æœ‰ç‰¹æƒï¼Œæ–°å®¹å™¨ä¹Ÿè¦æœ‰
                if host_config.get('Privileged'):
                    create_kwargs["privileged"] = True

                # å®‰å…¨é‡æ„ç­–ç•¥ï¼šå…ˆé‡å‘½åæ—§å®¹å™¨ï¼Œå¤±è´¥åˆ™å›æ»š
                old_name = container.name
                bak_name = f"{old_name}_lens_bak_{int(time.time())}"
                
                try:
                    container.stop()
                    container.rename(bak_name)
                    
                    # åˆ›å»ºå¹¶å¯åŠ¨æ–°å®¹å™¨
                    self.client.containers.run(**create_kwargs)
                    
                    # æ–°å®¹å™¨å¯åŠ¨æˆåŠŸï¼Œåˆ é™¤å¤‡ä»½
                    container.remove(force=True)
                    logger.info(f"âœ¨ [Docker] å®¹å™¨ {old_name} é‡æ„æˆåŠŸï¼Œå·²æ¸…ç†æ—§å®¹å™¨")
                except Exception as run_err:
                    logger.error(f"âŒ [Docker] æ–°å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œå°è¯•å›æ»š: {run_err}")
                    # å°è¯•æ¢å¤æ—§å®¹å™¨
                    try:
                        # æ£€æŸ¥æ–°å®¹å™¨æ˜¯å¦å·²åŠé€”åˆ›å»ºï¼ˆå¦‚æœåˆ›å»ºäº†ä½†æ²¡å¯åŠ¨æˆåŠŸï¼Œä¹Ÿéœ€è¦æ¸…ç†æ‰åç§°å ä½ï¼‰
                        try:
                            failed_new = self.client.containers.get(old_name)
                            failed_new.remove(force=True)
                        except: pass
                        
                        container.rename(old_name)
                        container.start()
                        logger.info(f"âª [Docker] å·²æˆåŠŸå›æ»šè‡³æ—§å®¹å™¨ {old_name}")
                    except Exception as rollback_err:
                        logger.error(f"ğŸš¨ [Docker] å›æ»šå¤±è´¥! æ—§å®¹å™¨ç›®å‰åç§°ä¸º {bak_name}: {rollback_err}")
                    raise run_err
            
            # æ“ä½œåæ¸…ç†åˆ—è¡¨ç¼“å­˜
            cache_keys = [f"{self.host_id}_True", f"{self.host_id}_False"]
            for k in cache_keys:
                if k in self._containers_cache:
                    del self._containers_cache[k]
            
            return True
        except Exception as e:
            logger.error(f"Error performing action {action} on container {container_id}: {e}")
            return False

    def get_container_logs(self, container_id: str, tail=100) -> str:
        if not self.client: return "Not connected to Docker"
        try:
            container = self.client.containers.get(container_id)
            return container.logs(tail=tail).decode("utf-8")
        except Exception as e:
            return str(e)

    async def get_image_update_info(self, image_tag: str):
        """
        è·å–é•œåƒçš„æ›´æ–°ä¿¡æ¯ã€‚æ”¯æŒ Docker Hub ä»¥åŠç¬¬ä¸‰æ–¹ä»“åº“ (å¦‚ lscr.io, ghcr.io)ã€‚
        """
        if not image_tag: return None
        
        # 1. è§£æé•œåƒåä¸ä»“åº“åœ°å€
        # lscr.io/linuxserver/qbittorrent:latest -> host=lscr.io, repo=linuxserver/qbittorrent, tag=latest
        # nginx -> host=registry-1.docker.io, repo=library/nginx, tag=latest
        parts = image_tag.split("/")
        host = "registry-1.docker.io"
        repo = ""
        tag = "latest"
        
        full_repo_path = image_tag
        if ":" in image_tag:
            full_repo_path, tag = image_tag.rsplit(":", 1)
            
        if "." in parts[0] or ":" in parts[0]:
            host = parts[0]
            repo = "/".join(parts[1:])
            if ":" in repo: repo = repo.rsplit(":", 1)[0]
        else:
            repo = full_repo_path
            if "/" not in repo:
                repo = f"library/{repo}"
        
        # ä¿®æ­£ Docker Hub çš„ä¸»æœºå
        reg_host = host
        if host == "docker.io": reg_host = "registry-1.docker.io"
            
        # 2. è·å–æœ¬åœ° RepoDigests
        local_digests = []
        res = self.exec_command(f"docker inspect --format='{{{{json .RepoDigests}}}}' {image_tag}", log_error=False)
        if res["success"] and res["stdout"].strip():
            try:
                import json
                local_digests = json.loads(res["stdout"])
            except: pass
            
        if not local_digests and self.client:
            try:
                img = self.client.images.get(image_tag)
                local_digests = img.attrs.get("RepoDigests", [])
            except: pass
            
        # 3. åŠ¨æ€è·å–è¿œç¨‹ Digest (æ”¯æŒ OCI æŒ‘æˆ˜è®¤è¯)
        remote_digest = ""
        try:
            from app.utils.http_client import get_async_client
            # æ‰©å±• Accept å¤´ï¼Œæ”¯æŒå¤šæ¶æ„é•œåƒæ¸…å•
            accept_headers = (
                "application/vnd.docker.distribution.manifest.v2+json, "
                "application/vnd.docker.distribution.manifest.list.v2+json, "
                "application/vnd.oci.image.manifest.v1+json, "
                "application/vnd.oci.image.index.v1+json"
            )
            
            async with get_async_client(timeout=15.0) as client:
                manifest_url = f"https://{reg_host}/v2/{repo}/manifests/{tag}"
                headers = {"Accept": accept_headers}
                
                # æ˜¾å¼å¼€å¯é‡å®šå‘è·Ÿéš
                res = await client.get(manifest_url, headers=headers, follow_redirects=True)
                
                if res.status_code == 401:
                    auth_header = res.headers.get("WWW-Authenticate", "")
                    if "Bearer" in auth_header:
                        import re
                        realm = re.search(r'realm="([^"]+)"', auth_header).group(1)
                        service_match = re.search(r'service="([^"]+)"', auth_header)
                        service = service_match.group(1) if service_match else ""
                        scope_match = re.search(r'scope="([^"]+)"', auth_header)
                        scope = scope_match.group(1) if scope_match else f"repository:{repo}:pull"
                        
                        auth_params = {"scope": scope}
                        if service: auth_params["service"] = service
                        
                        auth_res = await client.get(realm, params=auth_params, follow_redirects=True)
                        if auth_res.status_code == 200:
                            token = auth_res.json().get("token") or auth_res.json().get("access_token")
                            headers["Authorization"] = f"Bearer {token}"
                            res = await client.get(manifest_url, headers=headers, follow_redirects=True)
                
                if res.status_code == 200:
                    remote_digest = res.headers.get("Docker-Content-Digest", "")
                else:
                    logger.debug(f"HTTP {res.status_code} for {manifest_url}")
        except Exception as e:
            logger.warning(f"Failed to fetch remote digest for {image_tag} on {host}: {e}")

        # 4. å¯¹æ¯”åˆ¤å®š
        has_update = False
        if remote_digest:
            is_latest = any(remote_digest in d for d in local_digests)
            has_update = not is_latest
            status_text = "å‘ç°æ–°ç‰ˆæœ¬" if has_update else "å·²æ˜¯æœ€æ–°"
            logger.info(f"ğŸ” [é•œåƒæ£€æµ‹] ç«™ç‚¹: {host} | é•œåƒ: {repo}:{tag}")
            logger.info(f"   â”£ æœ¬åœ°æŒ‡çº¹: {local_digests}")
            logger.info(f"   â”£ è¿œç¨‹æŒ‡çº¹: {remote_digest}")
            logger.info(f"   â”— åˆ¤å®šç»“æœ: {status_text}")
        else:
            logger.warning(f"âš ï¸ [é•œåƒæ£€æµ‹] æ— æ³•è·å–è¿œç¨‹æŒ‡çº¹: {image_tag} (Host: {host})")

        return {
            "image": image_tag,
            "local_digests": local_digests,
            "remote_digest": remote_digest,
            "has_update": has_update
        }

    @staticmethod
    async def run_auto_update_task():
        """
        æè‡´ç²¾å‡†ç‰ˆï¼šæ ¹æ®è®°å½•ä¸­çš„ host_id ç›´æ¥å®šç‚¹æ›´æ–°
        """
        logger.info("ğŸš€ [Docker] å¼€å§‹æ‰§è¡Œæ¯æ—¥è‡ªåŠ¨æ›´æ–°ä»»åŠ¡...")
        from app.core.config_manager import get_config
        from app.services.notification_service import NotificationService
        
        config = get_config()
        # æ£€æŸ¥æ˜¯å¦å…¨å±€å¼€å¯äº†è‡ªåŠ¨æ›´æ–°
        auto_settings = config.get("docker_auto_update_settings", {"enabled": True})
        if not auto_settings.get("enabled"):
            logger.info("â„¹ï¸ [Docker] è‡ªåŠ¨æ›´æ–°å·²å…¨å±€å…³é—­ï¼Œè·³è¿‡æ‰§è¡Œã€‚")
            return

        all_hosts = config.get("docker_hosts", [])
        container_settings = config.get("docker_container_settings", {})
        
        # 1. ç­›é€‰å‡ºæ‰€æœ‰å¼€å¯äº†è‡ªåŠ¨æ›´æ–°ä¸”æœ‰ host_id çš„è®°å½•
        tasks_by_host = {}
        for name, settings in container_settings.items():
            if settings.get("auto_update") and settings.get("host_id"):
                h_id = settings.get("host_id")
                if h_id not in tasks_by_host:
                    tasks_by_host[h_id] = []
                tasks_by_host[h_id].append(name)
        
        if not tasks_by_host:
            logger.info("â„¹ï¸ [Docker] æ²¡æœ‰å‘ç°å¾…æ›´æ–°çš„ä»»åŠ¡è®°å½•ï¼Œä»»åŠ¡ç»“æŸã€‚")
            return

        updated_count = 0
        error_count = 0

        # 2. å®šç‚¹æ‰§è¡Œ
        for h_id, names in tasks_by_host.items():
            host_config = next((h for h in all_hosts if h.get("id") == h_id), None)
            if not host_config:
                logger.error(f"âŒ [Docker] æ‰¾ä¸åˆ° ID ä¸º {h_id} çš„ä¸»æœºé…ç½®ï¼Œè·³è¿‡å®¹å™¨: {names}")
                continue

            host_name = host_config.get("name", "Unknown")
            logger.info(f"ğŸŒ [Docker] æ­£åœ¨è¿æ¥ä¸»æœº [{host_name}] æ£€æŸ¥å®¹å™¨: {', '.join(names)}")
            
            try:
                from app.services.docker_service import DockerService
                service = DockerService(host_config)
                # ä½¿ç”¨ to_thread å¼‚æ­¥è·å–å®¹å™¨åˆ—è¡¨
                containers = await asyncio.to_thread(service.list_containers, True, {"name": names})
                
                for container in containers:
                    c_name = container.get("name")
                    if c_name in names:
                        image = container.get("image")
                        try:
                            update_info = await service.get_image_update_info(image)
                            if update_info and update_info.get("has_update"):
                                logger.info(f"âœ¨ [Docker][{host_name}] å‘ç°é•œåƒæ›´æ–°: {c_name}")
                                c_id = container.get("full_id") or container.get("id")
                                # ä½¿ç”¨ to_thread å¼‚æ­¥æ‰§è¡Œé‡æ„æ“ä½œ
                                if await asyncio.to_thread(service.container_action, c_id, "recreate"):
                                    updated_count += 1
                                    await NotificationService.emit(
                                        event="docker.auto_update",
                                        title="Docker è‡ªåŠ¨æ›´æ–°æˆåŠŸ",
                                        message=f"ä¸»æœº: {host_name}\nå®¹å™¨: {c_name}\né•œåƒ: {image}\nç»“æœ: å·²æ›´æ–°å¹¶é‡æ„"
                                    )
                                else:
                                    error_count += 1
                        except Exception as e:
                            logger.error(f"âŒ [Docker][{host_name}] å¤„ç† {c_name} å¼‚å¸¸: {e}")
                            error_count += 1
            except Exception as e:
                logger.error(f"âŒ [Docker] æ— æ³•è¿æ¥ä¸»æœº {host_name}: {e}")
                error_count += len(names)

        logger.info(f"ğŸ [Docker] è‡ªåŠ¨æ›´æ–°å®Œæ¯•ã€‚æ›´æ–°: {updated_count}, å¤±è´¥: {error_count}")

    _scheduler = None
    _is_running = False

    @classmethod
    def get_scheduler(cls):
        if cls._scheduler is None:
            from apscheduler.schedulers.asyncio import AsyncIOScheduler
            import os
            import pytz
            tz_name = os.getenv("TZ", "UTC")
            try:
                tz = pytz.timezone(tz_name)
            except Exception:
                tz = pytz.UTC
            cls._scheduler = AsyncIOScheduler(timezone=tz)
        return cls._scheduler

    @classmethod
    async def start_scheduler(cls):
        if not cls._is_running:
            cls.get_scheduler().start()
            cls._is_running = True
            logger.info("ğŸ“… [Docker] è‡ªåŠ¨æ›´æ–°è°ƒåº¦å™¨å·²å¯åŠ¨")
            await cls.reload_scheduler()

    @classmethod
    async def reload_scheduler(cls):
        """é‡è½½è°ƒåº¦å™¨è®¾ç½®"""
        from apscheduler.triggers.cron import CronTrigger
        from apscheduler.triggers.interval import IntervalTrigger
        from app.core.config_manager import get_config
        import os
        import pytz
        
        scheduler = cls.get_scheduler()
        scheduler.remove_all_jobs()
        
        config = get_config()
        settings = config.get("docker_auto_update_settings", {"enabled": True, "type": "cron", "value": "03:00"})
        
        if not settings.get("enabled"):
            logger.info("ğŸ“… [Docker] è‡ªåŠ¨æ›´æ–°å·²åœç”¨")
            return

        tz_name = os.getenv("TZ", "UTC")
        try:
            tz = pytz.timezone(tz_name)
        except Exception:
            tz = pytz.UTC

        try:
            stype = settings.get("type", "cron")
            sval = settings.get("value", "03:00")
            
            if stype == "cron":
                if ":" in sval:
                    h, m = sval.split(":")
                    trigger = CronTrigger(hour=int(h), minute=int(m), timezone=tz)
                else:
                    trigger = CronTrigger.from_crontab(sval, timezone=tz)
            else: # interval (minutes)
                trigger = IntervalTrigger(minutes=int(sval), timezone=tz)

            scheduler.add_job(
                DockerService.run_auto_update_task,
                trigger,
                id="docker_auto_update",
                replace_existing=True
            )
            logger.info(f"ğŸ“… [Docker] è‡ªåŠ¨æ›´æ–°å·²é‡è½½ ({stype}: {sval}, æ—¶åŒº: {tz_name})")
        except Exception as e:
            logger.error(f"âŒ [Docker] é‡è½½è°ƒåº¦å™¨å¤±è´¥: {e}")

    def test_connection(self) -> bool:
        if not self.client: return False
        try:
            self.client.ping()
            return True
        except Exception:
            return False

    def exec_command(self, command: str, cwd: Optional[str] = None, log_error: bool = True) -> Dict[str, Any]:
        """åœ¨è¿œç¨‹æˆ–æœ¬åœ°æ‰§è¡Œ shell å‘½ä»¤"""
        import subprocess
        full_cmd = f"cd {cwd} && {command}" if cwd else command
        
        # å™ªéŸ³è¿‡æ»¤å™¨ï¼šè¿‡æ»¤æ‰é‚£äº›æ— å®³ä½†çƒ¦äººçš„ Docker è­¦å‘Š
        noise_filters = [
            "the attribute `version` is obsolete",
            "search/all: the attribute `version` is obsolete",
            "recreate: the attribute `version` is obsolete"
        ]

        def filter_noise(text: str) -> str:
            if not text: return ""
            lines = text.split('\n')
            # åªæœ‰å½“è¯¥è¡Œä¸åŒ…å«ä»»ä½•å™ªéŸ³ç‰‡æ®µæ—¶æ‰ä¿ç•™
            filtered = [line for line in lines if not any(noise in line for noise in noise_filters)]
            return '\n'.join(filtered).strip()

        if self.host_config.get("type") == "local":
            try:
                process = subprocess.run(full_cmd, shell=True, capture_output=True, text=True, timeout=30)
                stdout = process.stdout
                stderr = filter_noise(process.stderr)
                
                if process.returncode != 0 and log_error:
                    logger.error(f"Local Command Failed: {command} (Code: {process.returncode}, Err: {stderr})")
                return {"success": process.returncode == 0, "stdout": stdout, "stderr": stderr}
            except Exception as e:
                return {"success": False, "stdout": "", "stderr": str(e)}
        
        elif self.host_config.get("type") == "ssh":
            ssh = None
            # å°è¯•ä»ç¼“å­˜è·å–
            if self.host_id in self._ssh_clients_cache:
                c, ts = self._ssh_clients_cache[self.host_id]
                # ç¼©çŸ­å¤ç”¨æ—¶é—´åˆ° 5 åˆ†é’Ÿï¼Œæé«˜å®‰å…¨æ€§
                if time.time() - ts < 300: 
                    try:
                        transport = c.get_transport()
                        if transport and transport.is_active():
                            # å‘é€ä¸€ä¸ªè½»é‡çº§å¿ƒè·³ä¿¡å·æ£€æŸ¥ Socket æ˜¯å¦çœŸçš„å¯ç”¨
                            transport.send_ignore()
                            ssh = c
                    except:
                        pass
            
            if not ssh:
                # æ¸…ç†å¤±æ•ˆç¼“å­˜
                if self.host_id in self._ssh_clients_cache:
                    try: self._ssh_clients_cache[self.host_id][0].close()
                    except: pass
                    del self._ssh_clients_cache[self.host_id]

                ssh = paramiko.SSHClient()
                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                try:
                    ssh_host = self.host_config.get("ssh_host")
                    ssh_user = self.host_config.get("ssh_user", "root")
                    ssh_port = self.host_config.get("ssh_port", 22)
                    ssh_pass = self.host_config.get("ssh_pass")
                    
                    ssh.connect(ssh_host, port=ssh_port, username=ssh_user, password=ssh_pass, timeout=10)
                    self._ssh_clients_cache[self.host_id] = (ssh, time.time())
                except Exception as e:
                    if log_error: logger.error(f"SSH Connection Error during exec: {e}")
                    return {"success": False, "stdout": "", "stderr": str(e)}

            try:
                # å¢åŠ  exec_command çš„è¶…æ—¶ä¿æŠ¤
                stdin, stdout, stderr = ssh.exec_command(full_cmd, timeout=30)
                
                out = stdout.read().decode()
                err = filter_noise(stderr.read().decode())
                exit_status = stdout.channel.recv_exit_status()
                
                if exit_status != 0 and log_error:
                    logger.error(f"SSH Command Failed: {command} (Code: {exit_status}, Err: {err})")
                
                return {
                    "success": exit_status == 0,
                    "stdout": out,
                    "stderr": err
                }
            except Exception as e:
                # å¦‚æœæ‰§è¡Œå¤±è´¥ä¸”æ˜¯å› ä¸ºè¿æ¥æ–­å¼€ï¼Œåˆ™æ¸…ç†ç¼“å­˜
                if self.host_id in self._ssh_clients_cache:
                    try: ssh.close()
                    except: pass
                    del self._ssh_clients_cache[self.host_id]
                if log_error: logger.error(f"SSH Exec Error: {e}")
                return {"success": False, "stdout": "", "stderr": str(e)}
        return {"success": False, "stdout": "", "stderr": "Unsupported host type"}

    def read_file(self, file_path: str) -> str:
        if self.host_config.get("type") == "local":
            if not os.path.exists(file_path): return ""
            with open(file_path, "r") as f: return f.read()
            
        elif self.host_config.get("type") == "ssh":
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            try:
                ssh.connect(self.host_config.get("ssh_host"), 
                            port=self.host_config.get("ssh_port", 22), 
                            username=self.host_config.get("ssh_user"), 
                            password=self.host_config.get("ssh_pass"),
                            timeout=10)
                sftp = ssh.open_sftp()
                with sftp.open(file_path, 'r') as f:
                    content = f.read().decode()
                sftp.close()
                return content
            except Exception as e:
                logger.error(f"SFTP Read Error: {e}")
                return ""
            finally:
                ssh.close()
        return ""

    def write_file(self, file_path: str, content: str) -> bool:
        if self.host_config.get("type") == "local":
            try:
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                with open(file_path, "w") as f: f.write(content)
                return True
            except: return False
            
        elif self.host_config.get("type") == "ssh":
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            try:
                ssh.connect(self.host_config.get("ssh_host"), 
                            port=self.host_config.get("ssh_port", 22), 
                            username=self.host_config.get("ssh_user"), 
                            password=self.host_config.get("ssh_pass"),
                            timeout=10)
                sftp = ssh.open_sftp()
                remote_dir = os.path.dirname(file_path)
                ssh.exec_command(f"mkdir -p {remote_dir}")
                with sftp.open(file_path, 'w') as f:
                    f.write(content)
                sftp.close()
                return True
            except Exception as e:
                logger.error(f"SFTP Write Error: {e}")
                return False
            finally:
                ssh.close()
        return False

    def get_container_socket(self, container_id: str, command: str = "/bin/bash"):
        """è·å–å®¹å™¨çš„äº¤äº’å¼ Socket"""
        if not self.client:
            return None
        
        try:
            # ä½¿ç”¨ APIClient ä»¥è·å¾—å¯¹åº•å±‚ socket çš„è®¿é—®æƒé™
            api_client = self.client.api
            exec_instance = api_client.exec_create(
                container_id, 
                cmd=command, 
                stdin=True, 
                stdout=True, 
                stderr=True, 
                tty=True
            )
            
            # è¿”å› socket ä¾› WebSocket ä½¿ç”¨
            sock = api_client.exec_start(exec_instance['Id'], detach=False, tty=True, stream=True, socket=True)
            return sock
        except Exception as e:
            logger.error(f"Failed to create exec socket: {e}")
            if command == "/bin/bash":
                # å°è¯•é€€å›åˆ° /bin/sh
                return self.get_container_socket(container_id, "/bin/sh")
            return None
