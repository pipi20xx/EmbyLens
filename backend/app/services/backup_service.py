import os
import time
import subprocess
import tarfile
import shutil
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from sqlalchemy import select, update
from app.db.session import AsyncSessionLocal
from app.models.backup import BackupHistory
from app.utils.logger import logger
from app.core.config_manager import get_config, save_config
from app.services.notification_service import NotificationService

class BackupService:
    _scheduler = None
    _is_running = False

    @classmethod
    def get_scheduler(cls):
        if cls._scheduler is None:
            import os
            import pytz
            tz_name = os.getenv("TZ", "UTC")
            try:
                tz = pytz.timezone(tz_name)
            except Exception:
                tz = pytz.UTC
            cls._scheduler = AsyncIOScheduler(timezone=tz)
        return cls._scheduler

    @classmethod
    async def start_scheduler(cls):
        if not cls._is_running:
            cls.get_scheduler().start()
            cls._is_running = True
            logger.info(f"â° [Backup] å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨ (æ—¶åŒº: {os.getenv('TZ', 'UTC')})")
            await cls.reload_tasks()

    @classmethod
    async def reload_tasks(cls):
        """ä» config.json åŠ è½½å¹¶é‡è½½æ‰€æœ‰å®šæ—¶ä»»åŠ¡"""
        scheduler = cls.get_scheduler()
        scheduler.remove_all_jobs()
        config = get_config()
        tasks = config.get("backup_tasks", [])
        
        import os
        import pytz
        tz_name = os.getenv("TZ", "UTC")
        try:
            tz = pytz.timezone(tz_name)
        except Exception:
            tz = pytz.UTC
        
        for task in tasks:
            if not task.get("enabled", True):
                continue
            
            try:
                task_id = task.get("id")
                schedule_type = task.get("schedule_type") # 'cron' or 'interval'
                schedule_value = task.get("schedule_value")
                
                if schedule_type == "cron":
                    trigger = CronTrigger.from_crontab(schedule_value, timezone=tz)
                elif schedule_type == "interval":
                    # å‡è®¾ value æ˜¯åˆ†é’Ÿ
                    trigger = IntervalTrigger(minutes=int(schedule_value), timezone=tz)
                else:
                    continue

                scheduler.add_job(
                    cls.run_backup_task,
                    trigger=trigger,
                    args=[task_id],
                    id=f"backup_{task_id}",
                    replace_existing=True
                )
                logger.info(f"âœ… [Backup] å·²æŒ‚è½½å®šæ—¶ä»»åŠ¡: {task.get('name')} ({schedule_value})")
            except Exception as e:
                logger.error(f"âŒ [Backup] åŠ è½½ä»»åŠ¡ {task.get('name')} å¤±è´¥: {e}")

    @classmethod
    async def run_backup_task(cls, task_id: str):
        """æ‰§è¡Œå¤‡ä»½ä»»åŠ¡çš„æ ¸å¿ƒå…¥å£"""
        config = get_config()
        tasks = config.get("backup_tasks", [])
        task = next((t for t in tasks if t.get("id") == task_id), None)
        
        if not task:
            logger.error(f"âŒ [Backup] æ‰¾ä¸åˆ°ä»»åŠ¡ ID: {task_id}")
            return

        # 1. åˆå§‹åŒ–æ‰§è¡Œè®°å½• (å¿«é€Ÿæäº¤ï¼Œé‡Šæ”¾è¿æ¥)
        history_id = None
        try:
            async with AsyncSessionLocal() as db:
                history = BackupHistory(
                    task_id=task_id,
                    task_name=task.get("name"),
                    mode=task.get("mode"),
                    status="running"
                )
                db.add(history)
                await db.commit()
                await db.refresh(history)
                history_id = history.id
        except Exception as e:
            logger.error(f"âŒ [Backup] åˆ›å»ºæ‰§è¡Œè®°å½•å¤±è´¥: {e}")
            # å³ä½¿è®°å½•åˆ›å»ºå¤±è´¥ï¼Œå¤‡ä»½ä»å°è¯•è¿è¡Œï¼Œä½†æ— æ³•åœ¨ UI æ˜¾ç¤ºè¿›åº¦

        start_time = time.time()
        logger.info(f"ğŸš€ [Backup] å¼€å§‹æ‰§è¡Œå¤‡ä»½ä»»åŠ¡: {task.get('name')}")
        
        success = False
        message = ""
        output_path = ""
        total_size = 0

        try:
            mode = task.get("mode", "7z")
            src = task.get("src_path")
            dst_dir = task.get("dst_path")
            
            if not os.path.exists(src):
                raise Exception(f"æºè·¯å¾„ä¸å­˜åœ¨: {src}")
            
            os.makedirs(dst_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = os.path.basename(src.rstrip("/"))
            
            if mode == "7z":
                output_path = os.path.join(dst_dir, f"{base_name}_{timestamp}.7z")
                success, message = await asyncio.to_thread(
                    cls._run_7z,
                    src, output_path, 
                    password=task.get("password"), 
                    ignore_patterns=task.get("ignore_patterns"),
                    level=task.get("compression_level", 1),
                    storage_type=task.get("storage_type", "ssd")
                )
            elif mode == "tar":
                output_path = os.path.join(dst_dir, f"{base_name}_{timestamp}.tar.gz")
                success, message = await asyncio.to_thread(cls._run_tar, src, output_path, task.get("ignore_patterns"))
            elif mode == "sync":
                output_path = os.path.join(dst_dir, base_name)
                success, message = await asyncio.to_thread(
                    cls._run_sync,
                    src, output_path, 
                    ignore_patterns=task.get("ignore_patterns"),
                    storage_type=task.get("storage_type", "ssd"),
                    strategy=task.get("sync_strategy", "mirror")
                )
            
            if success and output_path:
                if mode != "sync" and os.path.exists(output_path):
                    total_size = os.path.getsize(output_path) / (1024 * 1024) # MB
            
        except Exception as e:
            success = False
            message = str(e)
            logger.error(f"âŒ [Backup] ä»»åŠ¡ {task.get('name')} è¿è¡Œæ—¶å¼‚å¸¸: {e}")

        # 2. æ›´æ–°æ‰§è¡Œè®°å½• (ç¡®ä¿æœ€ç»ˆçŠ¶æ€å¾—åˆ°æ›´æ–°)
        if history_id:
            try:
                async with AsyncSessionLocal() as db:
                    await db.execute(
                        update(BackupHistory)
                        .where(BackupHistory.id == history_id)
                        .values(
                            status="success" if success else "failed",
                            end_time=datetime.now(),
                            size=total_size,
                            message=message[:500] if message else "", # é˜²æ­¢æ¶ˆæ¯è¿‡é•¿
                            output_path=output_path
                        )
                    )
                    await db.commit()
            except Exception as e:
                logger.error(f"âŒ [Backup] æ›´æ–°æ‰§è¡Œè®°å½•å¤±è´¥: {e}")
        
        duration = time.time() - start_time
        logger.info(f"ğŸ [Backup] ä»»åŠ¡ {task.get('name')} æ‰§è¡Œå®Œæ¯• (è€—æ—¶: {duration:.1f}s, çŠ¶æ€: {'æˆåŠŸ' if success else 'å¤±è´¥'})")

        # å‘é€é€šçŸ¥
        try:
            event = "backup.success" if success else "backup.failed"
            title = "å¤‡ä»½æˆåŠŸ" if success else "å¤‡ä»½å¤±è´¥"
            msg = f"ä»»åŠ¡: {task.get('name')}\næ¨¡å¼: {task.get('mode')}\nè€—æ—¶: {duration:.1f}s"
            if not success:
                msg += f"\né”™è¯¯: {message}"
            else:
                msg += f"\nå¤§å°: {total_size:.2f} MB"
                
            await NotificationService.emit(event, title, msg)
        except Exception as e:
            logger.warning(f"âš ï¸ [Backup] å‘é€é€šçŸ¥å¤±è´¥: {e}")
        
        duration = time.time() - start_time
        logger.info(f"ğŸ [Backup] ä»»åŠ¡ {task.get('name')} æ‰§è¡Œå®Œæ¯• (è€—æ—¶: {duration:.1f}s, çŠ¶æ€: {'æˆåŠŸ' if success else 'å¤±è´¥'})")

        # å‘é€é€šçŸ¥
        event = "backup.success" if success else "backup.failed"
        title = "å¤‡ä»½æˆåŠŸ" if success else "å¤‡ä»½å¤±è´¥"
        msg = f"ä»»åŠ¡: {task.get('name')}\næ¨¡å¼: {task.get('mode')}\nè€—æ—¶: {duration:.1f}s"
        if not success:
            msg += f"\né”™è¯¯: {message}"
        else:
            msg += f"\nå¤§å°: {total_size:.2f} MB"
            
        await NotificationService.emit(event, title, msg)

    @classmethod
    async def run_restore_task(cls, history_id: int, clear_dst: bool = False):
        """è¿˜åŸå¤‡ä»½çš„æ ¸å¿ƒå…¥å£"""
        async with AsyncSessionLocal() as db:
            # ... è·å– history å’Œ task çš„é€»è¾‘ä¿æŒä¸å˜ ...
            result = await db.execute(select(BackupHistory).where(BackupHistory.id == history_id))
            history = result.scalar_one_or_none()
            if not history:
                return False, "æœªæ‰¾åˆ°å†å²è®°å½•"
            
            config = get_config()
            tasks = config.get("backup_tasks", [])
            task = next((t for t in tasks if t.get("id") == history.task_id), None)
            
            if not task:
                return False, "æœªæ‰¾åˆ°å…³è”çš„ä»»åŠ¡é…ç½®"

            src_file = history.output_path
            dst_dir = task.get("src_path")
            mode = history.mode
            password = task.get("password")

            if not os.path.exists(src_file):
                return False, f"å¤‡ä»½æ–‡ä»¶å·²ä¸¢å¤±: {src_file}"

            # å¦‚æœå¼€å¯äº†æ¸…ç©ºè¿˜åŸ
            if clear_dst and os.path.exists(dst_dir):
                logger.warning(f"ğŸ§¹ [Backup] æ­£åœ¨æ¸…ç©ºç›®æ ‡ç›®å½•: {dst_dir}")
                try:
                    for item in os.listdir(dst_dir):
                        item_path = os.path.join(dst_dir, item)
                        if os.path.isfile(item_path) or os.path.islink(item_path):
                            os.unlink(item_path)
                        elif os.path.isdir(item_path):
                            shutil.rmtree(item_path)
                except Exception as e:
                    return False, f"æ¸…ç©ºç›®æ ‡ç›®å½•å¤±è´¥: {str(e)}"

            logger.info(f"âª [Backup] å¼€å§‹è¿˜åŸä»»åŠ¡ ({'æ¸…ç©º' if clear_dst else 'è¦†ç›–'}): {task.get('name')}")
            
            async def do_restore():
                try:
                    if mode == "7z":
                        cmd = ["7z", "x", src_file, f"-o{dst_dir}", "-y"]
                        if password: cmd.append(f"-p{password}")
                        res = subprocess.run(cmd, capture_output=True, text=True)
                        if res.returncode != 0: return False, res.stderr
                    
                    elif mode == "tar":
                        with tarfile.open(src_file, "r:gz") as tar:
                            tar.extractall(path=dst_dir)
                    
                    elif mode == "sync":
                        cmd = ["rsync", "-av", "--delete", src_file.rstrip("/") + "/", dst_dir.rstrip("/") + "/"]
                        res = subprocess.run(cmd, capture_output=True, text=True)
                        if res.returncode != 0: return False, res.stderr
                    return True, "è¿˜åŸæˆåŠŸ"
                except Exception as ex:
                    return False, str(ex)

            success, message = await asyncio.to_thread(lambda: asyncio.run(do_restore()) if asyncio.iscoroutinefunction(do_restore) else do_restore())
            # ç®€åŒ–ä¸€ä¸‹ï¼Œç›´æ¥åœ¨ thread è·‘åŒæ­¥é€»è¾‘
            def sync_restore():
                try:
                    if mode == "7z":
                        cmd = ["7z", "x", src_file, f"-o{dst_dir}", "-y"]
                        if password: cmd.append(f"-p{password}")
                        res = subprocess.run(cmd, capture_output=True, text=True)
                        if res.returncode != 0: return False, res.stderr
                    elif mode == "tar":
                        with tarfile.open(src_file, "r:gz") as tar:
                            tar.extractall(path=dst_dir)
                    elif mode == "sync":
                        cmd = ["rsync", "-av", "--delete", src_file.rstrip("/") + "/", dst_dir.rstrip("/") + "/"]
                        res = subprocess.run(cmd, capture_output=True, text=True)
                        if res.returncode != 0: return False, res.stderr
                    return True, "è¿˜åŸæˆåŠŸ"
                except Exception as ex: return False, str(ex)

            success, message = await asyncio.to_thread(sync_restore)
            
            if success:
                logger.info(f"âœ¨ [Backup] ä»»åŠ¡ {task.get('name')} è¿˜åŸæˆåŠŸ")
            else:
                logger.error(f"âŒ [Backup] è¿˜åŸå¤±è´¥: {message}")
                
            return success, message

    @staticmethod
    def _run_7z(src, dst, password=None, ignore_patterns=None, level=1, storage_type="ssd"):
        """è°ƒç”¨ 7z æ‰§è¡Œå¤‡ä»½ï¼Œä½¿ç”¨é¢„ç”Ÿæˆçš„æ¸…å•æ–‡ä»¶"""
        from app.utils.backup_filter import BackupFilter
        
        # 1. ç”Ÿæˆæ¸…å•æ–‡ä»¶
        list_file = f"{dst}.list.txt"
        flt = BackupFilter(ignore_patterns or [])
        file_count = flt.generate_file_list(src, list_file)
        
        if file_count == 0:
            if os.path.exists(list_file): os.remove(list_file)
            return False, "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆå¤‡ä»½æ¡ä»¶çš„æ–‡ä»¶"

        # 2. æ„é€  7z å‘½ä»¤ä½¿ç”¨æ¸…å•æ–‡ä»¶ (@)
        # æ³¨æ„ï¼š7z a dst @list_fileï¼Œæˆ‘ä»¬éœ€è¦åœ¨ src çš„çˆ¶ç›®å½•ä¸‹è¿è¡Œï¼Œè¿™æ ·ç›¸å¯¹è·¯å¾„æ‰æ­£ç¡®
        working_dir = os.path.dirname(src.rstrip("/"))
        
        cmd = ["7z", "a", dst, f"@{list_file}", f"-mx={level}"]
        
        if storage_type == "cloud":
            cmd.append("-mmt=on")
        elif storage_type == "hdd":
            cmd.append("-mmt=2")
        
        if password:
            cmd.append(f"-p{password}")
            cmd.append("-mhe=on")

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=working_dir)
            # æ¸…ç†ä¸´æ—¶æ¸…å•
            if os.path.exists(list_file): os.remove(list_file)
            
            if result.returncode == 0:
                return True, f"æˆåŠŸå¤‡ä»½ {file_count} ä¸ªæ–‡ä»¶"
            else:
                return False, result.stderr
        except Exception as e:
            if os.path.exists(list_file): os.remove(list_file)
            return False, str(e)

    @staticmethod
    def _run_tar(src, dst, ignore_patterns=None):
        """ä½¿ç”¨æ¸…å•æ–‡ä»¶æ‰§è¡Œ tar å¤‡ä»½ä»¥æ”¯æŒè¿‡æ»¤"""
        from app.utils.backup_filter import BackupFilter
        
        list_file = f"{dst}.list.txt"
        flt = BackupFilter(ignore_patterns or [])
        file_count = flt.generate_file_list(src, list_file)

        if file_count == 0:
            if os.path.exists(list_file): os.remove(list_file)
            return False, "æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶"

        working_dir = os.path.dirname(src.rstrip("/"))
        # ä½¿ç”¨ tar -T ä»æ¸…å•è¯»å–æ–‡ä»¶åˆ—è¡¨
        cmd = ["tar", "-czf", dst, "-T", list_file]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=working_dir)
            if os.path.exists(list_file): os.remove(list_file)
            
            if result.returncode == 0:
                return True, f"æˆåŠŸæ‰“åŒ… {file_count} ä¸ªæ–‡ä»¶"
            else:
                return False, result.stderr
        except Exception as e:
            if os.path.exists(list_file): os.remove(list_file)
            return False, str(e)

    @staticmethod
    def _run_sync(src, dst, ignore_patterns=None, storage_type="ssd", strategy="mirror"):
        """ä½¿ç”¨ rsync æ‰§è¡Œå¢é‡åŒæ­¥"""
        try:
            # åŸºç¡€å‚æ•°ï¼šå½’æ¡£æ¨¡å¼ã€è¯¦ç»†è¾“å‡º
            cmd = ["rsync", "-av"]
            
            # å¦‚æœæ˜¯é•œåƒæ¨¡å¼ï¼Œåˆ™æ·»åŠ  --delete ä»¥åˆ é™¤ç›®æ ‡ç›®å½•ä¸­å¤šä½™çš„æ–‡ä»¶
            if strategy == "mirror":
                cmd.append("--delete")
            
            # é’ˆå¯¹ä¸åŒå­˜å‚¨ä»‹è´¨çš„ä¼˜åŒ–
            if storage_type == "cloud":
                cmd.extend(["--no-owner", "--no-group", "--no-perms", "--size-only"])
            elif storage_type == "hdd":
                # æœºæ¢°ç¡¬ç›˜ï¼šå‡å°‘éšæœº IO å‹åŠ›
                pass
            
            cmd.extend([src.rstrip("/") + "/", dst.rstrip("/") + "/"])
            
            if ignore_patterns:
                for p in ignore_patterns:
                    cmd.append(f"--exclude={p}")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                return True, "OK"
            else:
                return False, result.stderr
        except Exception as e:
            return False, str(e)

    @staticmethod
    def get_history(limit=50):
        """è·å–æœ€è¿‘çš„å¤‡ä»½è®°å½•"""
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å¼‚æ­¥å¤„ç†ï¼Œæš‚æ—¶ä»…å®šä¹‰æ¥å£
        pass
