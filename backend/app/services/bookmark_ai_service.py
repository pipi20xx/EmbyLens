import json
import time
import asyncio
from typing import List, Dict, Any, AsyncGenerator, Optional
from app.services.ai_service import AIService
from app.services.config_service import ConfigService
from app.services.bookmark_service import get_data, save_data
from app.utils.logger import logger

class BookmarkAIService:
    # ç³»ç»Ÿé»˜è®¤åˆ†ç±»ï¼ˆå…œåº•ï¼‰
    DEFAULT_CATEGORIES = [
        "AI ä¸æ™ºèƒ½å·¥å…·", "æŠ€æœ¯ä¸å¼€å‘", "è®¾è®¡ä¸åˆ›æ„", "åŠå…¬ä¸æ•ˆç‡", "å½±éŸ³ä¸å¨±ä¹", 
        "åŠ¨æ¼«ä¸æ¸¸æˆ", "é˜…è¯»ä¸èµ„è®¯", "ç”Ÿæ´»ä¸è´­ç‰©", "çŸ¥è¯†ä¸æ•™è‚²", "å…¶ä»–å½’æ¡£"
    ]

    @classmethod
    async def run_auto_organize(cls, target_folder_id: Optional[str] = None) -> AsyncGenerator[str, None]:
        """å…¨é‡æ—¥å¿— + ä¸“å®¶çº§æ¸…æ´— + ä¸¥æ ¼æ‹¦æˆªé€»è¾‘"""
        data = get_data()
        bookmarks = data.get("bookmarks", [])
        
        # 1. è·å–æœ€æ–°åˆ†ç±»é¢„è®¾
        categories = await ConfigService.get("ai_bookmark_categories", cls.DEFAULT_CATEGORIES)
        if not categories or not isinstance(categories, list):
            categories = cls.DEFAULT_CATEGORIES

        # 2. æ‰«ææ•°æ®
        folder_map = {str(b["id"]): b["title"] for b in bookmarks if b["type"] == "folder"}
        
        target_ids = None
        if target_folder_id and target_folder_id != 'root':
            target_ids = {target_folder_id}
            changed = True
            while changed:
                changed = False
                for b in bookmarks:
                    if b["type"] == "folder" and str(b.get("parent_id")) in target_ids:
                        if str(b["id"]) not in target_ids:
                            target_ids.add(str(b["id"]))
                            changed = True
        
        all_files = []
        for b in bookmarks:
            if b.get("type") == "file":
                pid = str(b.get("parent_id"))
                if target_ids and pid not in target_ids and str(b["id"]) != target_folder_id:
                    continue
                
                parent_name = folder_map.get(pid, "æ ¹ç›®å½•")
                all_files.append({
                    "id": b["id"],
                    "title": b["title"],
                    "url": b.get("url", ""),
                    "current_folder": parent_name
                })
        
        total = len(all_files)
        if total == 0:
            yield "æœªæ‰¾åˆ°å¾…å¤„ç†çš„ä¹¦ç­¾ã€‚"
            return

        yield f"ğŸš€ [å¯åŠ¨] æ€»è®¡å¾…å¤„ç†ä¹¦ç­¾: {total}ï¼Œç›®æ ‡åˆ†ç±»æ•°: {len(categories)}"
        logger.info(f"ğŸ¤– [AIä¹¦ç­¾æ•´ç†] ä¸“å®¶æ¨¡å¼+ä¸¥æ ¼é™åˆ¶å¯åŠ¨ï¼Œæ€»æ•°: {total}")

        # 3. åˆ†æ‰¹å¤„ç†
        BATCH_SIZE = 20 
        for i in range(0, total, BATCH_SIZE):
            batch = all_files[i:i + BATCH_SIZE]
            current_range = f"{i+1}-{min(i+BATCH_SIZE, total)}"
            
            yield f"æ­£åœ¨åˆ†æç¬¬ {current_range} ä¸ªä¹¦ç­¾..."
            logger.info(f"ğŸ›°ï¸ [AIè¯·æ±‚] æ­£åœ¨æ·±åº¦å¤„ç†æ‰¹æ¬¡: {current_range}")
            
            prompt = f"""
            # Role
            ä½ æ˜¯ä¸€ä½æ‹¥æœ‰æè‡´å®¡ç¾å’Œå¼ºè¿«ç—‡é€»è¾‘çš„ä¹¦ç­¾æ•´ç†ä¸“å®¶ã€‚
            
            # STRICT LIMIT (å¼ºåˆ¶çº¦æŸ)
            ä½ ã€åªèƒ½ã€‘å°†ä¹¦ç­¾å½’ç±»åˆ°ä»¥ä¸‹æä¾›çš„åˆ†ç±»åä¸­ï¼š
            ---
            {', '.join(categories)}
            ---
            ã€ä¸¥ç¦ã€‘åˆ›å»ºä»»ä½•æ–°åˆ†ç±»åã€‚å¦‚æœä¸ç¡®å®šï¼Œè¯·ç»Ÿä¸€åˆ†é…åˆ°â€œå…¶ä»–å½’æ¡£â€ä¸­ã€‚
            
            # Task
            å¯¹ä¸‹æ–¹çš„ä¹¦ç­¾è¿›è¡Œã€è¯­ä¹‰åŒ–æ ‡é¢˜æ¸…æ´—ã€‘å’Œã€å¼ºåˆ¶ç²¾å‡†å½’ç±»ã€‘ã€‚
            
            # Rules
            1. **æ·±åº¦æ ‡é¢˜æ¸…æ´—**ï¼š
               - ç§»é™¤æ‰€æœ‰å†—ä½™åç¼€ï¼ˆå¦‚ï¼š- é¦–é¡µ, | çŸ¥ä¹, _CSDNåšå®¢, - å®˜ç½‘, - å“”å“©å“”å“©ï¼‰ã€‚
               - è¯­ä¹‰åŒ–é‡æ„ï¼šå¦‚æœåŸæ ‡é¢˜æ™¦æ¶©ï¼ˆå¦‚çº¯URLï¼‰ï¼Œè¯·æ ¹æ® URL è¯­ä¹‰èµ·ä¸€ä¸ªç›´è§‚çš„ä¸­æ–‡åã€‚
               - ä¿æŒç®€æ´ï¼šæœ€ç»ˆæ ‡é¢˜å»ºè®®æ§åˆ¶åœ¨ 10 ä¸ªä¸­æ–‡å­—ç¬¦ä»¥å†…ã€‚
               - å“ç‰Œä¿æŠ¤ï¼šä¿ç•™æ ¸å¿ƒå“ç‰Œåï¼ˆå¦‚ï¼šGitHub, Docker, Emby, Steam, ChatGPTï¼‰ã€‚
            2. **å¼ºåˆ¶å½’ç±»**ï¼š
               - æ¯ä¸€ä¸ªä¹¦ç­¾ ID å¿…é¡»åˆ†é…ä¸€ä¸ªæ¥è‡ªä¸Šè¿°åˆ—è¡¨çš„åˆ†ç±»ã€‚
            
            # Data
            {json.dumps(batch, ensure_ascii=False)}
            
            # Output (Strict JSON)
            {{
              "updates": {{
                 "ID": {{ "folder": "åˆ†ç±»å", "title": "æ–°æ ‡é¢˜" }}
              }}
            }}
            """
            
            try:
                response_text = await AIService.chat_json([
                    {"role": "system", "content": "ä½ åªè¿”å› JSONã€‚ä¸¥ç¦åˆ›å»ºæ–°åˆ†ç±»ã€‚"},
                    {"role": "user", "content": prompt}
                ])
                
                clean_json = response_text.strip()
                if clean_json.startswith("```"):
                    clean_json = clean_json.split("\n", 1)[1].rsplit("\n", 1)[0].strip()
                if clean_json.startswith("json"):
                    clean_json = clean_json[4:].strip()

                suggestions = json.loads(clean_json)
                
                # --- åç«¯å¼ºåŠ›æ‹¦æˆªé€»è¾‘ ---
                updates = suggestions.get("updates", {})
                for b_id, info in updates.items():
                    target_f = info.get("folder")
                    if target_f not in categories:
                        logger.warning(f"ğŸ›¡ï¸ [æ‹¦æˆª] AI å°è¯•åˆ›å»ºåˆ†ç±» '{target_f}'ï¼Œå·²å¼ºåˆ¶é‡å®šå‘è‡³ 'å…¶ä»–å½’æ¡£'")
                        info["folder"] = "å…¶ä»–å½’æ¡£"
                
                suggestions["folders"] = categories
                cls._apply_batch(suggestions)
                
                # é¢—ç²’åŒ–æ—¥å¿—è¾“å‡º
                for b_id, info in updates.items():
                    orig = next((b for b in batch if str(b['id']) == b_id), None)
                    orig_name = orig['title'] if orig else "æœªçŸ¥"
                    msg = f"ğŸ“ [{info['folder']}] {orig_name} -> {info['title']}"
                    yield msg
                    logger.info(f"âœ¨ [AI] {msg}")
                
            except Exception as e:
                err_msg = f"âš ï¸ å¤„ç†æ‰¹æ¬¡ {current_range} å‡ºé”™: {str(e)}"
                yield err_msg
                logger.error(f"âŒ [AIæ•´ç†é”™è¯¯] {err_msg}")

        yield "ğŸ§¹ æ­£åœ¨æ”¶å°¾ï¼šé€’å½’æ¸…ç†æ—§ç©ºç›®å½•..."
        cls._recursive_cleanup()
        
        yield "ğŸ‰ ä»»åŠ¡å®Œæˆï¼ä¹¦ç­¾æ ‘å·²æˆåŠŸè§„èŒƒåŒ–ã€‚"
        logger.info("ğŸ‰ [AIä¹¦ç­¾æ•´ç†] å…¨æµç¨‹ç»“æŸã€‚")

    @classmethod
    def _apply_batch(cls, suggestions: Dict):
        data = get_data()
        bookmarks = data.get("bookmarks", [])
        now_ms = int(time.time() * 1000)
        
        folder_name_to_id = {b["title"]: str(b["id"]) for b in bookmarks if b["type"] == "folder"}
        
        for f_name in suggestions.get("folders", []):
            if f_name not in folder_name_to_id:
                f_id = f"bm_ai_fld_{now_ms}_{f_name}"
                bookmarks.append({
                    "id": f_id, "type": "folder", "title": f_name, "parent_id": None, "order": 0
                })
                folder_name_to_id[f_name] = f_id
        
        updates = suggestions.get("updates", {})
        for i, bm in enumerate(bookmarks):
            bm_id = str(bm["id"])
            if bm_id in updates:
                info = updates[bm_id]
                bookmarks[i]["title"] = info.get("title", bm["title"])
                target_f = info.get("folder")
                if target_f in folder_name_to_id:
                    bookmarks[i]["parent_id"] = folder_name_to_id[target_f]
        
        save_data(data)

    @classmethod
    def _recursive_cleanup(cls):
        data = get_data()
        def do_cleanup():
            bookmarks = data.get("bookmarks", [])
            used_ids = {str(b.get("parent_id")) for b in bookmarks if b.get("parent_id")}
            new_list = []
            removed = 0
            for b in bookmarks:
                if b["type"] == "folder" and str(b["id"]) not in used_ids:
                    removed += 1
                    continue
                new_list.append(b)
            data["bookmarks"] = new_list
            return removed
        while True:
            if do_cleanup() == 0: break
        save_data(data)