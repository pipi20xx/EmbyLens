from fastapi import APIRouter, Depends, HTTPException, Body, BackgroundTasks, Request
from pydantic import BaseModel
from typing import List, Dict, Any, Optional, Literal
from app.core.config_manager import get_config, save_config
from app.core.tagger import Tagger
from app.utils.logger import logger, audit_log
from .autotag_helper import AutotagEmbyHelper
from app.utils.http_client import get_async_client
import httpx
import time
import uuid
import asyncio
import json

router = APIRouter()

# --- å…¨é‡å¤åˆ»ï¼šWebhook é˜Ÿåˆ—ä¸åå°å¤„ç† ---
webhook_queue = asyncio.Queue()

# --- 1:1 å¤åˆ»åŸé¡¹ç›®çš„å›½å®¶/è¯­è¨€æ˜ å°„è¡¨ ---
LANG_TO_COUNTRY = {
    "en": "ç¾å›½", "zh": "ä¸­å›½å¤§é™†", "ja": "æ—¥æœ¬", "ko": "éŸ©å›½", "fr": "æ³•å›½", "de": "å¾·å›½",
    "es": "è¥¿ç­ç‰™", "it": "æ„å¤§åˆ©", "hi": "å°åº¦", "ar": "æ²™ç‰¹é˜¿æ‹‰ä¼¯", "pt": "å·´è¥¿", "ru": "ä¿„ç½—æ–¯",
    "th": "æ³°å›½", "sv": "ç‘å…¸", "da": "ä¸¹éº¦", "no": "æŒªå¨", "nl": "è·å…°", "pl": "æ³¢å…°",
}

# æ‰©å±•æ˜ å°„ï¼šæ”¯æŒä» ISO å›½å®¶ä»£ç æ˜ å°„åˆ°ä¸­æ–‡
COUNTRY_CODE_TO_NAME = {
    "JP": "æ—¥æœ¬", "CN": "ä¸­å›½å¤§é™†", "US": "ç¾å›½", "KR": "éŸ©å›½", "TW": "ä¸­å›½å°æ¹¾", "HK": "ä¸­å›½é¦™æ¸¯",
    "FR": "æ³•å›½", "DE": "å¾·å›½", "GB": "è‹±å›½", "IT": "æ„å¤§åˆ©", "ES": "è¥¿ç­ç‰™", "CA": "åŠ æ‹¿å¤§",
    "IN": "å°åº¦", "TH": "æ³°å›½", "RU": "ä¿„ç½—æ–¯", "BR": "å·´è¥¿", "AU": "æ¾³å¤§åˆ©äºš"
}

# --- è¯·æ±‚æ¨¡å‹ ---
class AutoTagRule(BaseModel):
    name: str
    tag: str
    item_type: str = "all"
    match_all_conditions: bool = False
    is_negative_match: bool = False
    conditions: Dict[str, Any]

class TagActionRequest(BaseModel):
    mode: Literal['merge', 'overwrite'] = 'merge'
    library_type: Literal['all', 'favorite'] = 'all'
    custom_tags: Optional[List[str]] = None

async def get_helper():
    config = get_config()
    url = config.get("url")
    if not url: raise HTTPException(status_code=400, detail="æœªé…ç½® Emby æœåŠ¡å™¨")
    token = config.get("session_token") or config.get("api_key")
    return AutotagEmbyHelper(url, token, config.get("user_id")), config

async def fetch_tmdb_details(tmdb_key: str, tmdb_id: str, media_type: str):
    url = f"https://api.themoviedb.org/3/{media_type}/{tmdb_id}"
    params = {"api_key": tmdb_key, "language": "zh-CN"}
    async with get_async_client(timeout=15.0) as client:
        try:
            logger.info(f"â”ƒ  â”ƒ  ğŸŒ [TMDB] å‘èµ·è¯·æ±‚: {url}")
            resp = await client.get(url, params=params)
            if resp.status_code == 200:
                return resp.json()
            else:
                logger.warning(f"â”ƒ  â”ƒ  âš ï¸ TMDB API å“åº”å¼‚å¸¸: {resp.status_code}")
                return None
        except Exception as e:
            logger.error(f"â”ƒ  â”ƒ  âŒ TMDB è¯·æ±‚å¤±è´¥: {str(e)}")
            return None

# --- Webhook å¤„ç†æ ¸å¿ƒé€»è¾‘ (1:1 ç»“æ„å¤åˆ») ---

async def process_webhook_item(payload: Dict):
    """å¤„ç†æ¥è‡ª Webhook çš„å•ä¸ªé¡¹ç›®"""
    config = get_config()
    wh_cfg = config.get("webhook", {})
    if not wh_cfg.get("automation_enabled"): 
        logger.info("â”ƒ  [Webhook] è‡ªåŠ¨å¤„ç†å·²å…³é—­ï¼Œè·³è¿‡æ‰§è¡Œ")
        return
    
    # 1. è·å–é¡¹ç›®ä¿¡æ¯
    item = payload.get("Item", {})
    item_id = item.get("Id")
    item_name = item.get("Name")
    item_type = item.get("Type")
    
    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯å‰§é›†(Episode)æˆ–å­£åº¦(Season)ï¼Œè½¬è€Œå¤„ç†å…¶æ‰€å±çš„å‰§é›†ç³»åˆ—(Series)
    if item_type in ["Episode", "Season"]:
        series_id = item.get("SeriesId")
        if series_id:
            logger.info(f"â”ƒ  ğŸ“º æ£€æµ‹åˆ°{item_type}å…¥åº“ï¼Œå°†è‡ªåŠ¨å¤„ç†å…¶æ‰€å±å‰§é›†ç³»åˆ— (ID: {series_id})")
            # é‡æ–°è·å–ç³»åˆ—çš„ä¿¡æ¯
            helper, _ = await get_helper()
            series_item = await helper.get_item_full_detail(series_id)
            if series_item:
                item = series_item
                item_id = series_id
                item_name = item.get("Name")
                item_type = item.get("Type")
            else:
                logger.error(f"â”ƒ  âŒ æ— æ³•è·å–æ‰€å±å‰§é›†ç³»åˆ—è¯¦æƒ…: {series_id}")
                return

    tmdb_id = item.get("ProviderIds", {}).get("Tmdb")
    
    if not tmdb_id:
        logger.warning(f"â”ƒ  âš ï¸ [Webhook] é¡¹ç›®ç¼ºå°‘ TMDB IDï¼Œæ— æ³•è‡ªåŠ¨åŒ–: {item_name} (Type: {item_type})")
        return
        
    if item_type not in ["Movie", "Series"]: 
        return
    
    # å»¶è¿Ÿæ‰§è¡Œï¼Œç­‰å¾… Emby å…ƒæ•°æ®åŒæ­¥å®Œæˆ
    delay = wh_cfg.get("delay_seconds", 10)
    logger.info(f"â³ [Webhook] ä»»åŠ¡å¯åŠ¨ï¼Œç­‰å¾… {delay}s ä»¥ç¡®ä¿ Emby å…ƒæ•°æ®å°±ç»ª: {item_name}")
    await asyncio.sleep(delay)
    
    # 2. æ‰§è¡Œæ‰“æ ‡ç­¾é€»è¾‘
    helper, _ = await get_helper()
    tagger = Tagger(config.get("autotag_rules", []))
    tmdb_key = config.get("tmdb_api_key")
    
    m_type = "movie" if item_type == "Movie" else "tv"
    logger.info(f"â”ƒ  â”£ ğŸŒ [Webhook TMDB] æ­£åœ¨è·å–è¯¦æƒ…: {item_name} (TMDB ID: {tmdb_id})")
    details = await fetch_tmdb_details(tmdb_key, tmdb_id, m_type)
    if not details: 
        logger.error(f"â”ƒ  â”ƒ  âŒ [Webhook TMDB] è·å–è¯¦æƒ…å¤±è´¥: {item_name}")
        return
    
    # å…ƒæ•°æ®è§£æ
    genre_ids = [str(g["id"]) for g in details.get("genres", [])]
    genre_names = [g["name"] for g in details.get("genres", [])]
    countries = [c.upper() for c in details.get("origin_country", [])]
    
    year_str = details.get("release_date") or details.get("first_air_date") or "0000"
    year = int(year_str[:4]) if year_str else 0
    
    props = {"countries": countries, "genre_names": genre_ids, "year": year, "type": item_type}
    
    log_countries = [COUNTRY_CODE_TO_NAME.get(c, c) for c in countries]
    logger.info(f"â”ƒ  â”ƒ  ğŸ“‹ [Webhook å…ƒæ•°æ®] å›½å®¶: {log_countries} ({countries}) | ç±»å‹: {genre_names} ({genre_ids}) | å¹´ä»½: {year}")
    
    target_tags = tagger.generate_tags(props)
    if target_tags:
        logger.info(f"â”ƒ  â”ƒ  ğŸ¯ [Webhook åŒ¹é…] ç›®æ ‡æ ‡ç­¾: {target_tags}")
        await helper.update_item_metadata(item_id, target_tags, wh_cfg.get("write_mode", "merge"))
    else:
        logger.info(f"â”ƒ  â”ƒ  ğŸŸ¡ [Webhook è·³è¿‡] æ— è§„åˆ™åŒ¹é…: {item_name}")

async def webhook_worker():
    """æ— é™å¾ªç¯çš„åå° Webhook æ¶ˆè´¹è€…"""
    logger.info("ğŸ“¡ [Webhook] è‡ªåŠ¨æ ‡ç­¾åå°ç›‘å¬å·²å¯åŠ¨")
    while True:
        payload = await webhook_queue.get()
        try:
            await process_webhook_item(payload)
        except Exception as e:
            logger.error(f"âŒ [Webhook] å¤„ç†å¤±è´¥: {e}")
        finally:
            webhook_queue.task_done()

# --- ä»»åŠ¡æ‰§è¡Œæµ (1:1 ç»“æ„å¤åˆ») ---

async def run_autotag_task_isolated(request: TagActionRequest):
    helper, config = await get_helper()
    tagger = Tagger(config.get("autotag_rules", []))
    tmdb_key = config.get("tmdb_api_key")
    logger.info(f"ğŸš€ [è‡ªåŠ¨æ ‡ç­¾] ä»»åŠ¡å¯åŠ¨...")
    
    all_items = await helper.get_all_items()
    if request.library_type == 'favorite': 
        all_items = [i for i in all_items if i.get("UserData", {}).get("IsFavorite")]
        logger.info(f"â”ƒ  â­ å·²è¿‡æ»¤ä»…é™æ”¶è—é¡¹ç›®ï¼Œå¾…å¤„ç†æ•°é‡: {len(all_items)}")
    else:
        logger.info(f"â”ƒ  ğŸ“¦ å¾…å¤„ç†æ€»æ•°: {len(all_items)}")

    updated = 0
    for i, item in enumerate(all_items):
        item_name = item.get("Name", "Unknown")
        item_id = item.get("Id")
        try:
            tmdb_id = item.get("ProviderIds", {}).get("Tmdb")
            if not tmdb_id:
                logger.info(f"â”ƒ  ğŸ•’ [{i+1}/{len(all_items)}] è·³è¿‡ (æ—  TMDB ID): {item_name}")
                continue
            
            logger.info(f"â”ƒ  ğŸ•’ [{i+1}/{len(all_items)}] æ­£åœ¨å¤„ç†: {item_name}")
            
            m_type = "movie" if item.get("Type") == "Movie" else "tv"
            details = await fetch_tmdb_details(tmdb_key, tmdb_id, m_type)
            if not details:
                logger.warning(f"â”ƒ  â”ƒ  âš ï¸ è·³è¿‡: æ— æ³•è·å– TMDB è¯¦æƒ…")
                continue

            # --- å…ƒæ•°æ®è§£æ ---
            genre_ids = [str(g["id"]) for g in details.get("genres", [])]
            genre_names = [g["name"] for g in details.get("genres", [])]
            
            # å›½å®¶ï¼šç›´æ¥ä½¿ç”¨ ISO ä»£ç è¿›è¡ŒåŒ¹é…
            countries = [c.upper() for c in details.get("origin_country", [])]
            
            # å¦‚æœæ²¡æœ‰å›½å®¶ä»£ç ï¼Œå°è¯•ä»åŸå§‹è¯­è¨€æ˜ å°„ï¼ˆä½œä¸ºå…œåº•ï¼‰
            if not countries:
                lang = details.get("original_language")
                # è¿™é‡Œä¾ç„¶å¯ä»¥ç”¨æ˜ å°„ï¼Œä½†å­˜å…¥ props çš„åº”è¯¥æ˜¯ä»£ç 
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨ details é‡Œçš„åŸå§‹æ•°æ®
                pass

            year_str = details.get("release_date") or details.get("first_air_date") or "0000"
            year = int(year_str[:4]) if year_str else 0
            
            # props ç°åœ¨å­˜å‚¨ ID å’Œ CODE
            props = {"countries": countries, "genre_names": genre_ids, "year": year, "type": item.get("Type")}
            
            # æ—¥å¿—è¾“å‡ºï¼šè½¬æ¢å›ä¸­æ–‡æ–¹ä¾¿äººç±»é˜…è¯»
            log_countries = [COUNTRY_CODE_TO_NAME.get(c, c) for c in countries]
            logger.info(f"â”ƒ  â”ƒ  ğŸ“‹ [å…ƒæ•°æ®] å›½å®¶: {log_countries} ({countries}) | ç±»å‹: {genre_names} ({genre_ids}) | å¹´ä»½: {year}")
            
            target_tags = request.custom_tags if request.custom_tags else tagger.generate_tags(props)
            
            if target_tags:
                logger.info(f"â”ƒ  â”ƒ  ğŸ¯ [åŒ¹é…] ç›®æ ‡æ ‡ç­¾: {target_tags}")
                if await helper.update_item_metadata(item_id, target_tags, request.mode): 
                    updated += 1
            else:
                logger.info(f"â”ƒ  â”ƒ  ğŸŸ¡ [è·³è¿‡] æ— è§„åˆ™åŒ¹é…")

        except Exception as e:
            logger.error(f"â”ƒ  â”ƒ  âŒ å¤„ç†å‡ºé”™ [{item_name}]: {str(e)}")
        
        # å¼ºåˆ¶å°ä¼‘ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
        if i % 5 == 0: await asyncio.sleep(0.1)
        
    logger.info(f"âœ… [è‡ªåŠ¨æ ‡ç­¾] å®Œæˆï¼Œæ›´æ–°: {updated}")

async def run_clear_task_isolated(tags_to_remove: Optional[List[str]] = None):
    helper, _ = await get_helper()
    logger.warning(f"ğŸ”¥ [æ ‡ç­¾æ¸…ç†] å¯åŠ¨")
    all_items = await helper.get_all_items()
    logger.info(f"â”ƒ  ğŸ“¦ æ‰«æå®Œæˆï¼Œå¾…å¤„ç†é¡¹ç›®æ•°: {len(all_items)}")
    
    cleared = 0
    for i, item in enumerate(all_items):
        item_name = item.get("Name", "Unknown")
        try:
            if tags_to_remove is None:
                # æ¸…ç†æ‰€æœ‰æ ‡ç­¾
                if await helper.update_item_metadata(item["Id"], [], mode='overwrite'): 
                    cleared += 1
            else:
                # æ¸…ç†æŒ‡å®šæ ‡ç­¾
                if await helper.remove_specific_tags(item["Id"], tags_to_remove): 
                    cleared += 1
        except Exception as e:
            logger.error(f"â”ƒ  â”ƒ  âŒ æ¸…ç†å‡ºé”™ [{item_name}]: {str(e)}")
            
        if i > 0 and i % 50 == 0:
            logger.info(f"â”ƒ  ğŸ•’ æ¸…ç†è¿›åº¦: {i}/{len(all_items)}...")
            
    logger.info(f"âœ… [æ ‡ç­¾æ¸…ç†] ç»“æŸï¼Œå½±å“é¡¹ç›®æ•°: {cleared}")

# --- è·¯ç”±æ¥å£ ---

@router.post("/webhook/{token}")
async def receive_webhook(token: str, payload: Dict = Body(...)):
    """æ¥æ”¶å¹¶åˆ†å‘ Webhook"""
    wh_cfg = get_config().get("webhook", {})
    event = payload.get("Event")
    item = payload.get("Item", {})
    item_name = item.get("Name", "Unknown")
    
    # ç¬¬ä¸€æ—¶é—´æ‰“å‡ºæ”¶åˆ°çš„æ‰€æœ‰ Webhook æ¦‚è¦ï¼Œä¸å¸¦ä»»ä½•è¿‡æ»¤
    logger.info(f"ğŸ“¡ [Webhook] æ”¶åˆ°è¯·æ±‚ | äº‹ä»¶: {event} | é¡¹ç›®: {item_name} | Tokenæ ¡éªŒ: {'é€šè¿‡' if token == wh_cfg.get('secret_token') else 'å¤±è´¥'}")
    
    # æ‰“å°å®Œæ•´ Payload ä¾›ç”¨æˆ·æ’æŸ¥
    logger.info(f"ğŸ“¦ [Webhook Payload] åŸå§‹æ•°æ®æ˜ç»†:\n{json.dumps(payload, indent=2, ensure_ascii=False)}")

    if not wh_cfg.get("enabled"): 
        logger.warning(f"â”ƒ  âš ï¸ Webhook åŠŸèƒ½åœ¨è®¾ç½®ä¸­å·²è¢«ç¦ç”¨")
        raise HTTPException(status_code=403, detail="Webhook disabled")
        
    if token != wh_cfg.get("secret_token"): 
        logger.error(f"â”ƒ  âŒ æä¾›çš„ Token ({token}) ä¸é…ç½®ä¸åŒ¹é…")
        raise HTTPException(status_code=401, detail="Invalid token")
    
    # æ‰©å¤§åŒ¹é…èŒƒå›´ï¼Œè®°å½•ä¸‹å…·ä½“è¢«å¿½ç•¥çš„åŸå› 
    target_events = ["item.added", "ItemAdded", "LibraryChanged", "library.new"]
    if event in target_events:
        logger.info(f"â”ƒ  âœ… å‘½ä¸­ç›®æ ‡äº‹ä»¶ï¼Œå·²å…¥é˜Ÿç­‰å¾…å¤„ç†...")
        await webhook_queue.put(payload)
        return {"status": "queued"}
    
    logger.info(f"â”ƒ  ğŸŸ¡ å¿½ç•¥éè‡ªåŠ¨åŒ–ç›®æ ‡äº‹ä»¶: {event}")
    return {"status": "ignored", "event": event}

@router.get("/rules")
async def get_rules(): return get_config().get("autotag_rules", [])

@router.post("/rules")
async def save_rules(rules: List[AutoTagRule]):
    config = get_config()
    config["autotag_rules"] = [r.dict() for r in rules]
    save_config(config)
    return {"message": "ok"}

@router.post("/test-write")
async def test_tag_write(item_id: str = Body(..., embed=True), tag: str = Body(..., embed=True)):
    helper, _ = await get_helper()
    return {"success": await helper.update_item_metadata(item_id, [tag], mode='merge')}

@router.post("/execute")
async def execute_task(request: TagActionRequest, background_tasks: BackgroundTasks):
    background_tasks.add_task(run_autotag_task_isolated, request)
    return {"message": "ok"}

@router.post("/clear-all")
async def clear_all(background_tasks: BackgroundTasks):
    background_tasks.add_task(run_clear_task_isolated, None)
    return {"message": "ok"}

@router.post("/clear-specific")
async def clear_specific(tags: List[str] = Body(..., embed=True), background_tasks: BackgroundTasks = None):
    background_tasks.add_task(run_clear_task_isolated, tags)
    return {"message": "ok"}

@router.get("/webhook-config")
async def get_wh_config():
    wh = get_config().get("webhook", {})
    return wh

@router.post("/webhook-config")
async def save_wh_config(data: Dict = Body(...)):
    config = get_config()
    config["webhook"] = data
    save_config(config)
    return {"message": "ok"}