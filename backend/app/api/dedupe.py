from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, delete, or_
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from app.db.session import get_db
from app.models.media import MediaItem
from app.services.emby import EmbyService
from app.core.scorer import Scorer
from app.core.config_manager import get_config, save_config
from app.utils.logger import logger, audit_log
import time
import re
from collections import defaultdict

router = APIRouter()

# --- è¾…åŠ©é€»è¾‘ ---
SEARCH_FIELD_MAP = { "åç§°": "name", "è·¯å¾„": "path", "å¹´ä»½": "year", "embyid": "id", "tmdb": "tmdb_id" }

def parse_advanced_search(text: str):
    criteria = {}
    pattern = re.compile(r'(\w+):(?:"([^"]*)"|(\S+))')
    for match in pattern.finditer(text):
        field, quoted_value, unquoted_value = match.groups()
        field_key = field.lower()
        val = (quoted_value if quoted_value is not None else unquoted_value).strip()
        db_field = SEARCH_FIELD_MAP.get(field_key) or SEARCH_FIELD_MAP.get(field)
        if db_field: criteria[db_field] = val
    return criteria

async def get_emby_context(db: AsyncSession):
    config = get_config()
    url = config.get("url")
    if not url: raise HTTPException(status_code=400, detail="æœªé…ç½® Emby æœåŠ¡å™¨")
    token = config.get("session_token") or config.get("api_key")
    return EmbyService(url, token, config.get("user_id"), config.get("tmdb_api_key"))

class BulkDeleteRequest(BaseModel):
    item_ids: List[str]

import asyncio

# --- æ¥å£å®ç° ---

@router.post("/sync")
async def sync_media(db: AsyncSession = Depends(get_db)):
    """åŒæ­¥ Emby åª’ä½“æ•°æ®ï¼Œæ”¯æŒ 10 å¹¶å‘å¹¶è¡Œæ‹‰å–"""
    start_time = time.time()
    service = await get_emby_context(db)
    logger.info("ğŸš€ [åŒæ­¥] å¯åŠ¨é«˜å¹¶å‘åŒæ­¥å¼•æ“ (Concurrency: 10)...")
    
    unique_items = {} 
    item_to_series_tmdb = {}

    async def fetch_paged(types, p_id=None):
        fetched = []
        limit = 300
        start = 0
        while True:
            params = {
                "IncludeItemTypes": ",".join(types), "Recursive": "true",
                "Fields": "Path,ProductionYear,ProviderIds,MediaStreams,DisplayTitle,SortName,ParentId,SeriesId,SeasonId,IndexNumber,ParentIndexNumber",
                "StartIndex": start, "Limit": limit
            }
            if p_id: params["ParentId"] = p_id
            resp = await service._request("GET", "/Items", params=params)
            if not resp or resp.status_code != 200: break
            batch = resp.json().get("Items", [])
            if not batch: break
            fetched.extend(batch)
            if len(batch) < limit: break
            start += limit
        return fetched

    # 1. æŠ“å– Movie å’Œ Series
    top_items = await fetch_paged(["Movie", "Series"])
    for i in top_items:
        unique_items[i["Id"]] = i
        if i.get("Type") == "Series":
            tmdb = i.get("ProviderIds", {}).get("Tmdb")
            if tmdb: item_to_series_tmdb[i["Id"]] = tmdb
    
    # 2. å¹¶è¡Œå¤„ç†å‰§é›†å­é¡¹
    series_items = [i for i in top_items if i.get("Type") == "Series"]
    total_series = len(series_items)
    logger.info(f"â”£ ğŸ“‚ å‡†å¤‡å¹¶å‘å¤„ç† {total_series} ä¸ªå‰§é›†çš„å­é¡¹...")

    # ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
    sem = asyncio.Semaphore(10)
    processed_count = 0

    async def process_single_series(s_item):
        nonlocal processed_count
        async with sem:
            s_tmdb = item_to_series_tmdb.get(s_item["Id"])
            children = await fetch_paged(["Season", "Episode"], p_id=s_item["Id"])
            for child in children:
                # ç»§æ‰¿é€»è¾‘
                if s_tmdb and not child.get("ProviderIds", {}).get("Tmdb"):
                    if "ProviderIds" not in child: child["ProviderIds"] = {}
                    child["ProviderIds"]["Tmdb"] = s_tmdb
                unique_items[child["Id"]] = child
            
            processed_count += 1
            if processed_count % 20 == 0 or processed_count == total_series:
                logger.info(f"â”ƒ  ğŸ•’ åŒæ­¥è¿›åº¦: {processed_count}/{total_series}...")

    # å¯åŠ¨å¹¶è¡Œä»»åŠ¡
    tasks = [process_single_series(s) for s in series_items]
    await asyncio.gather(*tasks)
    
    # 3. å…¥åº“æ“ä½œ
    logger.info(f"â”£ ğŸ’¾ æ­£åœ¨å°† {len(unique_items)} æ¡æ•°æ®å­˜å…¥æœ¬åœ°åº“...")
    await db.execute(delete(MediaItem))
    
    for item_id, item in unique_items.items():
        v = next((s for s in item.get("MediaStreams", []) if s.get("Type") == "Video"), {})
        a = next((s for s in item.get("MediaStreams", []) if s.get("Type") == "Audio"), {})
        
        s_num = item.get("ParentIndexNumber") if item.get("Type") == "Episode" else item.get("IndexNumber") if item.get("Type") == "Season" else None
        e_num = item.get("IndexNumber") if item.get("Type") == "Episode" else None
        p_id = item.get("SeasonId") or item.get("SeriesId") or item.get("ParentId")
        
        db.add(MediaItem(
            id=item["Id"], name=item.get("Name"), item_type=item.get("Type"),
            tmdb_id=item.get("ProviderIds", {}).get("Tmdb"), path=item.get("Path"),
            year=item.get("ProductionYear"), parent_id=p_id,
            season_num=s_num, episode_num=e_num,
            display_title=v.get("DisplayTitle", "N/A"), video_codec=v.get("Codec", "N/A"),
            video_range=v.get("VideoRange", "N/A"), audio_codec=a.get("Codec", "N/A"),
            raw_data=item
        ))
    
    await db.commit()
    audit_log("é«˜å¹¶å‘åŒæ­¥å®Œæˆ", (time.time()-start_time)*1000, [f"åŒæ­¥æ¡æ•°: {len(unique_items)}"])
    logger.info(f"âœ… [åŒæ­¥] æˆåŠŸï¼Œæ€»è®¡è€—æ—¶: {int(time.time()-start_time)}s")
    return {"message": "ok"}

@router.get("/items")
async def get_all_items(query_text: Optional[str] = None, item_type: Optional[str] = None, parent_id: Optional[str] = None, db: AsyncSession = Depends(get_db)):
    query = select(MediaItem)
    if query_text:
        if ":" in query_text:
            for f, v in parse_advanced_search(query_text).items():
                if f == "year":
                    try: query = query.where(MediaItem.year == int(v))
                    except: pass
                else: query = query.where(getattr(MediaItem, f).ilike(f"%{v}%"))
        else: query = query.where((MediaItem.name.ilike(f"%{query_text}%")) | (MediaItem.path.ilike(f"%{query_text}%")) | (MediaItem.id == query_text))
    if parent_id: query = query.where(MediaItem.parent_id == parent_id)
    elif not query_text:
        if item_type: query = query.where(MediaItem.item_type == item_type)
        else: query = query.where(MediaItem.item_type.in_(["Movie", "Series"]))
    result = await db.execute(query.order_by(MediaItem.name))
    return result.scalars().all()

@router.get("/duplicates")
async def list_duplicates(db: AsyncSession = Depends(get_db)):
    """è·å–æ‰€æœ‰é‡å¤çš„ç”µå½±ã€å‰§é›†æœ¬ä½“ã€å•é›†"""
    body_sub = select(MediaItem.tmdb_id).where(MediaItem.item_type.in_(["Movie", "Series"])).where(MediaItem.tmdb_id.isnot(None)).group_by(MediaItem.tmdb_id).having(func.count(MediaItem.id) > 1).subquery()
    bodies = await db.execute(select(MediaItem).where(MediaItem.tmdb_id.in_(select(body_sub))).where(MediaItem.item_type.in_(["Movie", "Series"])))
    
    ep_sub = select(MediaItem.tmdb_id, MediaItem.season_num, MediaItem.episode_num).where(MediaItem.item_type == "Episode").where(MediaItem.tmdb_id.isnot(None)).group_by(MediaItem.tmdb_id, MediaItem.season_num, MediaItem.episode_num).having(func.count(MediaItem.id) > 1).subquery()
    eps = await db.execute(select(MediaItem).join(ep_sub, (MediaItem.tmdb_id == ep_sub.c.tmdb_id) & (MediaItem.season_num == ep_sub.c.season_num) & (MediaItem.episode_num == ep_sub.c.episode_num)))
    
    res = []
    for item in list(bodies.scalars().all()) + list(eps.scalars().all()):
        res.append({"id": item.id, "name": item.name, "item_type": item.item_type, "path": item.path, "display_title": item.display_title, "video_codec": item.video_codec, "video_range": item.video_range, "tmdb_id": item.tmdb_id, "raw_data": item.raw_data, "is_duplicate": True})
    return res

@router.post("/smart-select")
async def smart_select_v4(db: AsyncSession = Depends(get_db)):
    """æ™ºèƒ½åˆ†æï¼Œæ”¯æŒåŒºåˆ†å‘½åç©ºé—´"""
    config = get_config()
    rule_data = config.get("dedupe_rules")
    exclude_paths = config.get("exclude_paths", [])
    scorer = Scorer(rule_data)
    
    all_items_res = await db.execute(select(MediaItem).where(MediaItem.item_type.in_(["Movie", "Series", "Episode"])))
    all_items = all_items_res.scalars().all()
    
    groups = defaultdict(list)
    for i in all_items:
        if not i.tmdb_id: continue
        if i.item_type == "Movie": key = f"Movie-{i.tmdb_id}"
        elif i.item_type == "Series": key = f"Series-{i.tmdb_id}"
        elif i.item_type == "Episode": key = f"TV-{i.tmdb_id}-S{str(i.season_num or 0).zfill(2)}E{str(i.episode_num or 0).zfill(2)}"
        else: continue
        groups[key].append(i)
        
    to_delete_ids = []
    for key, g_items in groups.items():
        if len(g_items) > 1:
            scored_data = [{"id": i.id, "emby_id": i.id, "path": i.path, "display_title": i.display_title, "video_codec": i.video_codec, "video_range": i.video_range} for i in g_items]
            suggested = scorer.select_best(scored_data)
            for eid in suggested:
                item_obj = next(it for it in g_items if it.id == eid)
                if not any(item_obj.path.startswith(ex) for ex in exclude_paths if ex.strip()):
                    to_delete_ids.append(eid)
    
    if not to_delete_ids: return []
    final_res = await db.execute(select(MediaItem).where(MediaItem.id.in_(to_delete_ids)))
    return final_res.scalars().all()

@router.delete("/items")
async def delete_items_optimized(request: BulkDeleteRequest, db: AsyncSession = Depends(get_db)):
    """ä¼˜åŒ–ç‰ˆåˆ é™¤ï¼šå¦‚æœçˆ¶èŠ‚ç‚¹ä¹Ÿè¦è¢«åˆ é™¤ï¼Œåˆ™è·³è¿‡å­èŠ‚ç‚¹çš„ API è°ƒç”¨"""
    start_time = time.time()
    service = await get_emby_context(db)
    
    # 1. é¢„å…ˆè·å–æ‰€æœ‰å¾…åˆ é™¤é¡¹ç›®çš„å±‚çº§ä¿¡æ¯
    res = await db.execute(select(MediaItem).where(MediaItem.id.in_(request.item_ids)))
    delete_map = {item.id: item for item in res.scalars().all()}
    
    # 2. è¯†åˆ«å¹¶æŠ˜å å†—ä½™æ“ä½œ
    final_ids_to_call = []
    skipped_count = 0
    
    for eid in request.item_ids:
        item = delete_map.get(eid)
        if not item: continue
        
        # å‘ä¸Šæº¯æºï¼šæ£€æŸ¥çˆ¶çº§æˆ–æ›´é«˜çº§ç¥–å…ˆæ˜¯å¦ä¹Ÿåœ¨åˆ é™¤åˆ—è¡¨ä¸­
        is_redundant = False
        current_p_id = item.parent_id
        while current_p_id:
            if current_p_id in request.item_ids:
                is_redundant = True
                break
            # è¿™é‡Œçš„ç®€å•å®ç°å‡è®¾ parent_id å·²ç»åœ¨ MediaItem é‡Œäº†ï¼Œ
            # å¦‚æœæ˜¯è·¨å±‚çº§ï¼ˆå¦‚ Series ç›´æ¥åˆ  Episodeï¼‰ï¼Œéœ€è¦æ•°æ®åº“äºŒæ¬¡è¾…åŠ©
            # ä½†åœ¨æˆ‘ä»¬çš„æŸ¥é‡é€»è¾‘ä¸­ï¼Œparent_id å·²ç»è¦†ç›–äº†æ ¸å¿ƒå±‚çº§ã€‚
            # è¿™é‡Œæˆ‘ä»¬é€šè¿‡æŸ¥è¯¢ç¡®ä¿å‡†ç¡®
            p_res = await db.execute(select(MediaItem.parent_id).where(MediaItem.id == current_p_id))
            current_p_id = p_res.scalar()
            
        if is_redundant:
            logger.info(f"âš¡ [ä¼˜åŒ–] è·³è¿‡å•é›† API è°ƒç”¨ (çˆ¶çº§å·²åœ¨æ¸…ç†åˆ—è¡¨): {item.path}")
            skipped_count += 1
        else:
            final_ids_to_call.append(eid)

    # 3. æ‰§è¡Œç‰©ç†åˆ é™¤
    success = 0
    for eid in final_ids_to_call:
        item = delete_map.get(eid)
        logger.warning(f"ğŸ”¥ [æ¸…ç†] æ‰§è¡Œ Emby åˆ é™¤: {item.path if item else eid}")
        if await service.delete_item(eid):
            success += 1
            # æ³¨æ„ï¼šå³ä¾¿ API æ²¡è°ƒï¼ˆè¢«æŠ˜å äº†ï¼‰ï¼Œæ•°æ®åº“é‡Œçš„è®°å½•ä¹Ÿè¦åˆ æ‰
            # è¿™é‡Œç»Ÿä¸€å¤„ç†
    
    # 4. ä»æœ¬åœ°åº“æ¸…ç†æ‰€æœ‰ä¼ å…¥çš„ ID (åŒ…å«è¢«æŠ˜å çš„å­é¡¹)
    await db.execute(delete(MediaItem).where(MediaItem.id.in_(request.item_ids)))
    await db.commit()
    
    audit_log("åª’ä½“æ¸…ç†ä»»åŠ¡æ‰§è¡Œå®Œæ¯•", (time.time()-start_time)*1000, [
        f"API è°ƒç”¨æ•°: {len(final_ids_to_call)}",
        f"è‡ªåŠ¨æŠ˜å å­é¡¹æ•°: {skipped_count}",
        f"æˆåŠŸæ•°: {success}"
    ])
    return {"success": success, "skipped": skipped_count}

@router.get("/config")
async def get_dedupe_config():
    config = get_config()
    return {"rules": config.get("dedupe_rules"), "exclude_paths": config.get("exclude_paths", [])}

@router.post("/config")
async def save_dedupe_config(data: Dict[str, Any]):
    config = get_config()
    if "rules" in data: config["dedupe_rules"] = data["rules"]
    if "exclude_paths" in data: config["exclude_paths"] = data["exclude_paths"]
    save_config(config)
    return {"message": "ok"}
